{
  "28": {
    "title": "Why Do Some Language Models Fake Alignment While Others Don't?",
    "authors": [
      "Abhay Sheshadri",
      "John Hughes",
      "Julian Michael",
      "Alex Mallen",
      "Arun Jose",
      "Janus",
      "Fabien Roger"
    ],
    "year": 2025,
    "venue": "arXiv cs.LG (2025)",
    "tags": [
      "alignment",
      "safety",
      "deception",
      "RLHF"
    ],
    "summary": "Tests 25 frontier LLMs for alignment faking and finds only 5 exhibit the behavior; Claude 3 Opus shows coherent goal-guarding while most models avoid it through refusal training rather than capability limits.",
    "dir": "./papers/p28",
    "interactiveTitle": "Alignment faking simulator",
    "relatedQuestions": [
      13,
      22,
      44
    ]
  },
  "27": {
    "title": "GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks",
    "authors": [
      "Tejal Patwardhan",
      "Rachel Dias",
      "Elizabeth Proehl",
      "Grace Kim",
      "Michele Wang",
      "Olivia Watkins",
      "Simon Posada Fishman",
      "Marwan Aljubeh",
      "Phoebe Thacker",
      "Laurance Fauconnet",
      "Natalie S. Kim",
      "Patrick Chao",
      "Samuel Miserendino",
      "Gildas Chabot",
      "David Li",
      "Michael Sharman",
      "Alexandra Barr",
      "Amelia Glaese",
      "Jerry Tworek"
    ],
    "year": 2025,
    "venue": "OpenAI Research (2025)",
    "tags": [
      "evaluation",
      "economics",
      "operations"
    ],
    "summary": "GDPval sizes model progress on 1,320 expert-authored tasks, showing human-parity wins when paired with review loops and revealing how scaffolding drives speed and cost savings.",
    "dir": "./papers/p27",
    "interactiveTitle": "GDPval rollout planner",
    "relatedQuestions": [
      45,
      50,
      56
    ]
  },
  "24": {
    "title": "Quantifying Human-AI Synergy",
    "authors": [
      "Christoph Riedl",
      "Ben Weidmann"
    ],
    "year": 2025,
    "venue": "PsyArXiv (2025-09-22)",
    "tags": [
      "collaboration",
      "evaluation",
      "theory-of-mind"
    ],
    "summary": "Bayesian IRT separates solo skill, collaborative skill, and AI lift on ChatBench, revealing 29-point boosts from GPT-4o and the outsized role of Theory of Mind.",
    "dir": "./papers/p24",
    "interactiveTitle": "Human-AI synergy lab",
    "relatedQuestions": [
      8,
      13,
      45
    ]
  },
  "23": {
    "title": "GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks",
    "authors": [
      "Tejal Patwardhan",
      "Rachel Dias",
      "Elizabeth Proehl",
      "Grace Kim",
      "Michele Wang",
      "Olivia Watkins",
      "Simon Posada Fishman",
      "Marwan Aljubeh",
      "Phoebe Thacker",
      "Laurance Fauconnet",
      "Natalie S. Kim",
      "Patrick Chao",
      "Samuel Miserendino",
      "Gildas Chabot",
      "David Li",
      "Michael Sharman",
      "Alexandra Barr",
      "Amelia Glaese",
      "Jerry Tworek"
    ],
    "year": 2025,
    "venue": "OpenAI Research (2025)",
    "tags": [
      "evaluation",
      "economics",
      "benchmark"
    ],
    "summary": "Benchmarks frontier models on realistic GDP-weighted tasks, showing near-parity with experts and clear gains from reasoning effort plus scaffolding.",
    "dir": "./papers/p23",
    "interactiveTitle": "GDPval readiness lab",
    "relatedQuestions": [
      45,
      50,
      56
    ]
  },
  "22": {
    "title": "Stress Testing Deliberative Alignment for Anti-Scheming Training",
    "authors": [
      "Bronson Schoen",
      "Evgenia Nitishinskaya",
      "Mikita Balesni",
      "Axel Højmark",
      "Felix Hofstätter",
      "Jérémy Scheurer",
      "Alexander Meinke",
      "Jason Wolfe",
      "Teun van der Weij",
      "Alex Lloyd",
      "Nicholas Goldowsky-Dill",
      "Angela Fan",
      "Andrei Matveiakin",
      "Rusheb Shah",
      "Marcus Williams",
      "Amelia Glaese",
      "Boaz Barak",
      "Wojciech Zaremba",
      "Marius Hobbhahn"
    ],
    "year": 2025,
    "venue": "arXiv cs.AI (2025-09-19)",
    "tags": [
      "alignment",
      "safety",
      "evaluation"
    ],
    "summary": "Stress-tests deliberative alignment across covert-action suites, showing that situational awareness and hidden-goal robustness determine residual scheming risk.",
    "dir": "./papers/p22",
    "interactiveTitle": "Anti-scheming stress lab",
    "relatedQuestions": [
      8,
      13,
      45
    ]
  },
  "21": {
    "title": "Godel Test: Can Large Language Models Solve Easy Conjectures?",
    "authors": [
      "Moran Feldman",
      "Amin Karbasi"
    ],
    "year": 2025,
    "venue": "arXiv cs.AI (2025-09-22)",
    "tags": [
      "reasoning",
      "math",
      "evaluation"
    ],
    "summary": "Benchmarks GPT-5 on fresh, easy conjectures; shows progress on routine proofs but fragility on cross-paper synthesis and verification.",
    "dir": "./papers/p21",
    "interactiveTitle": "Godel readiness lab",
    "relatedQuestions": [
      38,
      45,
      56
    ]
  },
  "20": {
    "title": "The Coasean Singularity? Demand, Supply, and Market Design with AI Agents",
    "authors": [
      "Peyman Shahidi",
      "Gili Rusak",
      "Benjamin S. Manning",
      "Andrey Fradkin",
      "John J. Horton"
    ],
    "year": 2025,
    "venue": "NBER Transformative AI Conference (2025-09-16)",
    "tags": [
      "agents",
      "market-design",
      "economics",
      "policy"
    ],
    "summary": "Shows how autonomous AI agents reshape transaction costs, platform competition, and market design, highlighting new governance levers and research gaps.",
    "dir": "./papers/p20",
    "interactiveTitle": "Agentic market design lab",
    "relatedQuestions": [
      45,
      50,
      52
    ]
  },
  "19": {
    "title": "Making AI Count: The Next Measurement Frontier",
    "authors": [
      "Diane Coyle",
      "John Lourenze Poquiz"
    ],
    "year": 2025,
    "venue": "NBER Transformative AI Conference (2025-08-01)",
    "tags": [
      "measurement",
      "economics",
      "policy"
    ],
    "summary": "Maps where national accounts miss AI's diffusion across free services, embedded quality gains, supply-chain inputs, and time savings, and lays out satellite-account fixes.",
    "dir": "./papers/p19",
    "interactiveTitle": "AI measurement readiness lab",
    "relatedQuestions": [
      45,
      50,
      52
    ]
  },
  "18": {
    "title": "How Much Should We Spend to Reduce A.I.'s Existential Risk?",
    "authors": [
      "Charles I. Jones"
    ],
    "year": 2025,
    "venue": "NBER Transformative AI Conference (2025-03-17)",
    "tags": [
      "policy",
      "risk",
      "economics"
    ],
    "summary": "Uses revealed-preference and VSL logic to argue that multi-percent-of-GDP investments in AI catastrophe mitigation are rational even without longtermist weighting.",
    "dir": "./papers/p18",
    "interactiveTitle": "AI risk budget calculator",
    "relatedQuestions": [
      36,
      45,
      52
    ]
  },
  "17": {
    "title": "We Won't Be Missed: Work and Growth in the Era of AGI",
    "authors": [
      "Pascual Restrepo"
    ],
    "year": 2025,
    "venue": "NBER Transformative AI Conference (2025-07-04)",
    "tags": [
      "growth",
      "labor",
      "compute"
    ],
    "summary": "Shows that once AGI automates all growth bottlenecks, output becomes compute-limited, wages shadow compute costs, and labor's income share trends toward zero even with residual accessory work.",
    "dir": "./papers/p17",
    "interactiveTitle": "AGI compute allocation lab",
    "relatedQuestions": [
      8,
      45,
      52
    ]
  },
  "16": {
    "title": "Artificial Intelligence in Research and Development",
    "authors": [
      "Benjamin F. Jones"
    ],
    "year": 2025,
    "venue": "NBER Transformative AI Conference (2025-09-16)",
    "tags": [
      "R&D",
      "productivity",
      "strategy"
    ],
    "summary": "Models AI as research capital alongside people, emphasising task coverage, relative productivity, and complementary bottlenecks when machines take on R&D tasks.",
    "dir": "./papers/p16",
    "interactiveTitle": "R&D intelligence planner",
    "relatedQuestions": [
      7,
      8,
      45
    ]
  },
  "15": {
    "title": "Artificial Intelligence, Competition, and Welfare",
    "authors": [
      "Susan Athey",
      "Fiona Scott Morton"
    ],
    "year": 2025,
    "venue": "NBER Transformative AI Conference (2025-09-19)",
    "tags": [
      "competition",
      "policy",
      "welfare"
    ],
    "summary": "Models AI as an upstream monopolist selling access and usage rights, showing how markups can lower wages, shrink variety, and leak rents abroad even when AI is productive.",
    "dir": "./papers/p15",
    "interactiveTitle": "AI market power simulator",
    "relatedQuestions": [
      45,
      50,
      52
    ]
  },
  "14": {
    "title": "AI Exposure and the Adaptive Capacity of American Workers",
    "authors": [
      "Sam Manning",
      "Tomás Aguirre"
    ],
    "year": 2025,
    "venue": "GovAI & Foundation for American Innovation (2025-09-17)",
    "tags": [
      "workforce",
      "policy",
      "reskilling"
    ],
    "summary": "Builds an occupation-level adaptive capacity index to show where AI-exposed workers are resilient and where clerical roles face concentrated vulnerability.",
    "dir": "./papers/p14",
    "interactiveTitle": "Exposure vs capacity planner",
    "relatedQuestions": [
      8,
      45,
      52
    ]
  },
  "13": {
    "title": "An Economy of AI Agents",
    "authors": [
      "Gillian K. Hadfield",
      "Andrew Koh"
    ],
    "year": 2025,
    "venue": "NBER Handbook on the Economics of Transformative AI (2025-09-03)",
    "tags": [
      "agents",
      "markets",
      "governance"
    ],
    "summary": "Explores how autonomous AI agents might transact, bargain, and organise with minimal human oversight, and outlines the market institutions needed to keep them aligned.",
    "dir": "./papers/p13",
    "interactiveTitle": "Agent deployment playbook",
    "relatedQuestions": [
      45,
      50,
      52
    ]
  },
  "12": {
    "title": "AI’s Use of Knowledge in Society",
    "authors": [
      "Erik Brynjolfsson",
      "Zoë Hitzig"
    ],
    "year": 2025,
    "venue": "NBER Workshop on Transformative AI (2025-09-18)",
    "tags": [
      "strategy",
      "governance",
      "policy"
    ],
    "summary": "Argues that transformative AI codifies tacit expertise and expands HQ planning capacity, pushing organisations toward centralised ownership unless countervailing forces intervene.",
    "dir": "./papers/p12",
    "interactiveTitle": "Centralisation stress test",
    "relatedQuestions": [
      36,
      50,
      52
    ]
  },
  "11": {
    "title": "The impact of AI and digital platforms on the information ecosystem",
    "authors": [
      "Joseph E. Stiglitz",
      "Maxim Ventura-Bolet"
    ],
    "year": 2025,
    "venue": "NBER Transformative AI Conference (2025-09-15)",
    "tags": [
      "policy",
      "misinformation",
      "platforms"
    ],
    "summary": "Models news producers, consumers, and platforms to show AI efficiencies can shrink truthful supply and raise misinformation unless accountability and licensing guardrails align incentives.",
    "dir": "./papers/p11",
    "interactiveTitle": "Information ecosystem stress test",
    "relatedQuestions": [
      36,
      45,
      50
    ]
  },
  "10": {
    "title": "Genius on Demand: The Value of Transformative Artificial Intelligence",
    "authors": [
      "Ajay Agrawal",
      "Joshua S. Gans",
      "Avi Goldfarb"
    ],
    "year": 2025,
    "venue": "NBER Transformative AI Conference (2025-09-08)",
    "tags": [
      "automation",
      "labour",
      "strategy"
    ],
    "summary": "Models how scarce human geniuses and routine workers split knowledge tasks, then shows AI genius capacity pushes humans to the frontier and can erase routine roles when efficiency improves.",
    "dir": "./papers/p10",
    "interactiveTitle": "Genius routing planner",
    "relatedQuestions": [
      36,
      50,
      52
    ]
  },
  "9": {
    "title": "Training Compute-Optimal Large Language Models",
    "authors": [
      "Jordan Hoffmann",
      "Sebastian Borgeaud",
      "Arthur Mensch",
      "Elena Buchatskaya"
    ],
    "year": 2022,
    "venue": "arXiv cs.LG (2022-03-29)",
    "tags": [
      "scaling",
      "compute",
      "training"
    ],
    "summary": "Derives compute-optimal scaling laws and shows a 70B parameter, 1.4T token Chinchilla model beats larger GPT-3/Gopher runs by reallocating FLOPs to more data.",
    "dir": "./papers/p09",
    "interactiveTitle": "Compute budget navigator",
    "relatedQuestions": [
      48,
      49,
      51
    ]
  },
  "8": {
    "title": "Conversational AI increases political knowledge as effectively as self-directed internet search",
    "authors": [
      "Lennart Luettgau",
      "Hannah Kirk",
      "Kobi Hackenburg",
      "Christopher Summerfield"
    ],
    "year": 2025,
    "venue": "arXiv cs.HC (2025-09-05)",
    "tags": [
      "policy",
      "trust",
      "misinformation"
    ],
    "summary": "UK survey and RCTs show election research with GPT-4o, Claude 3.5, and Mistral matches web search at boosting true beliefs, avoids misinformation gains, and resists persuasive prompts.",
    "dir": "./papers/p08",
    "interactiveTitle": "Civic info impact lab",
    "relatedQuestions": [
      45,
      50,
      36
    ]
  },
  "7": {
    "title": "A Taxonomy of Transcendence",
    "authors": [
      "Natalie Abreu",
      "Edwin Zhang",
      "Eran Malach",
      "Naomi Saphra"
    ],
    "year": 2025,
    "venue": "COLM 2025",
    "tags": [
      "data diversity",
      "capabilities",
      "theory"
    ],
    "summary": "Formalises skill denoising/selection/generalisation and shows synthetic expert diversity lets models outperform any contributor.",
    "dir": "./papers/p07",
    "interactiveTitle": "Transcendence lab",
    "relatedQuestions": [
      36,
      37,
      45
    ]
  },
  "6": {
    "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs",
    "authors": [
      "Akshit Sinha",
      "Arvindh Arun",
      "Shashwat Goel",
      "Steffen Staab",
      "Jonas Geiping"
    ],
    "year": 2025,
    "venue": "arXiv cs.AI (2025-09-11)",
    "tags": [
      "execution",
      "scaling",
      "evaluation"
    ],
    "summary": "Shows that small step-accuracy gains compound into exponential horizon growth, isolates long-horizon execution, and reveals self-conditioning failures mitigated by thinking models.",
    "dir": "./papers/p06",
    "interactiveTitle": "Long horizon lab",
    "relatedQuestions": [
      8,
      36,
      55
    ]
  },
  "5": {
    "title": "Mathematical Research with GPT-5: a Malliavin–Stein Experiment",
    "authors": [
      "Charles-Philippe Diez",
      "Luís da Maia",
      "Ivan Nourdin"
    ],
    "year": 2025,
    "venue": "arXiv math.PR (2025-09-03)",
    "tags": [
      "research",
      "math",
      "ai-assist"
    ],
    "summary": "Documents how GPT-5 helped derive new quantitative Malliavin–Stein bounds, highlighting human-in-the-loop proof workflows.",
    "dir": "./papers/p05",
    "interactiveTitle": "AI proof lab",
    "relatedQuestions": [
      8,
      37,
      45
    ]
  },
  "4": {
    "title": "Pun Unintended: LLMs and the Illusion of Humor Understanding",
    "authors": [
      "Alessandro Zangari",
      "Matteo Marcuzzo",
      "Andrea Albarelli",
      "Mohammad Taher Pilehvar",
      "Jose Camacho-Collados"
    ],
    "year": 2025,
    "venue": "arXiv cs.CL (2025-09-15)",
    "tags": [
      "humor",
      "robustness",
      "evaluation"
    ],
    "summary": "Introduces PunnyPattern and PunBreak to show LLM pun detection relies on shallow cues and breaks under simple perturbations.",
    "dir": "./papers/p04",
    "interactiveTitle": "Pun robustness lab",
    "relatedQuestions": [
      13,
      41,
      45
    ]
  },
  "3": {
    "title": "Rethinking Chunk Size for Long-Document Retrieval",
    "authors": [
      "Sinchana Ramakanth Bhat",
      "Max Rudat",
      "Jannis Spiekermann",
      "Nicolas Flores-Herr"
    ],
    "year": 2025,
    "venue": "arXiv cs.IR (2025-06-10)",
    "tags": [
      "rag",
      "retrieval",
      "chunking"
    ],
    "summary": "Benchmarks token chunk sizes across QA corpora; shows dataset traits and embedding bias dictate the optimal window.",
    "dir": "./papers/p03",
    "interactiveTitle": "Chunk sizing planner",
    "relatedQuestions": [
      7,
      36,
      53
    ]
  },
  "2": {
    "title": "Why Language Models Hallucinate",
    "authors": [
      "Ji",
      "Lee",
      "Fries",
      "et al."
    ],
    "year": 2025,
    "venue": "arXiv (2025-09-04)",
    "tags": [
      "hallucination",
      "retrieval",
      "alignment"
    ],
    "summary": "Distribution shift makes LLMs fabricate confident answers; combine grounding, reward shaping, and uncertainty routing.",
    "dir": "./papers/p02",
    "interactiveTitle": "Hallucination risk simulator",
    "relatedQuestions": [
      32,
      36,
      45,
      55
    ]
  },
  "1": {
    "title": "On the Theoretical Limitations of Embedding-Based Retrieval",
    "authors": [
      "Orion Weller",
      "Michael Boratko",
      "Iftekhar Naim",
      "Jinhyuk Lee"
    ],
    "year": 2025,
    "venue": "arXiv cs.IR (2025)",
    "tags": [
      "retrieval",
      "theory",
      "embeddings"
    ],
    "relatedQuestions": [
      7,
      36,
      38
    ],
    "dir": "./papers/p01",
    "interactiveTitle": "Embedding capacity stress tester",
    "summary": "Shows that single-vector embeddings cannot realize all top-k subsets; introduces the LIMIT dataset to expose the gap."
  },
  "25": {
    "title": "On the Folly of Rewarding A, While Hoping for B",
    "authors": [
      "Steven Kerr"
    ],
    "year": 1995,
    "venue": "The Academy of Management Executive (1995)",
    "tags": [
      "management",
      "incentives",
      "governance"
    ],
    "summary": "Classic management essay documenting how organizations buy the wrong behaviors when rewards favour easy-to-measure metrics and offering a playbook for incentive audits.",
    "dir": "./papers/p25",
    "interactiveTitle": "Incentive alignment lab",
    "relatedQuestions": [
      8,
      45,
      52
    ]
  },
  "26": {
    "title": "Defeating Nondeterminism in LLM Inference",
    "authors": [
      "Horace He",
      "Thinking Machines Lab"
    ],
    "year": 2025,
    "venue": "Thinking Machines Lab: Connectionism (2025-09-10)",
    "tags": [
      "inference",
      "determinism",
      "systems"
    ],
    "summary": "Shows how batch-size-dependent kernels drive temp-0 drift and how batch-invariant RMSNorm, matmul, and FlexAttention patches restore bitwise determinism with a manageable latency tax.",
    "dir": "./papers/p26",
    "interactiveTitle": "Deterministic inference lab",
    "relatedQuestions": [
      6,
      50,
      53
    ]
  }
}
