<div class="space-y-5">
  <div class="bg-indigo-50 border border-indigo-200 rounded-lg p-4">
    <div class="flex flex-wrap md:flex-nowrap items-start justify-between gap-4">
      <div class="md:max-w-3xl">
        <h2 class="text-xl font-semibold text-indigo-900">A Taxonomy of Transcendence</h2>
        <p class="text-sm text-indigo-700">Natalie Abreu, Edwin Zhang, Eran Malach, Naomi Saphra ‚Ä¢ COLM 2025 (arXiv:2508.17669)</p>
      </div>
      <a href="https://arxiv.org/abs/2508.17669" target="_blank" rel="noopener" class="inline-flex items-center gap-2 px-3 py-1.5 rounded-md text-xs font-medium bg-white border border-indigo-200 text-indigo-700 hover:bg-indigo-100">
        <span>View paper</span>
        <span aria-hidden="true" class="text-sm leading-none">‚Üó</span>
      </a>
    </div>
    <p class="mt-3 text-sm text-indigo-800 leading-relaxed">
      The authors formalise when an imitative language model can outperform every individual data source it learns from. They derive three ‚Äútranscendence‚Äù modes‚Äîskill denoising, skill selection, and skill generalisation‚Äîthen prove and test the data diversity conditions that unlock each one using a synthetic knowledge-graph of fictional experts.
    </p>
  </div>

  <div class="bg-slate-900 text-slate-100 border border-slate-800 rounded-lg p-5 space-y-3">
    <div class="flex items-center gap-2">
      <span class="text-lg">üß≠</span>
      <h3 class="text-sm font-semibold tracking-wide uppercase text-slate-200">Executive quick take</h3>
    </div>
    <p class="text-sm text-slate-200 leading-relaxed">
      ‚ÄúAnthropomorphising‚Äù a model‚Äîtreating it like a single human mind‚Äîmisses the point: it is trained to mimic a <em>mixture</em> of experts. If your dataset blends uncorrelated errors, differentiated expertise, and compositional examples, the resulting model can denoise, route, and recombine knowledge beyond any single contributor.
    </p>
    <ul class="list-disc ml-5 text-sm text-slate-300 space-y-1">
      <li><strong>Denoise noise:</strong> Low-temperature decoding concentrates the majority vote when mistakes are independent.</li>
      <li><strong>Select specialists:</strong> Exposure-weighted sampling lets the model surface the right expert per context.</li>
      <li><strong>Compose skills:</strong> Rich multi-hop demonstrations bias the model toward latent structure over memorisation.</li>
    </ul>
  </div>

  <div class="bg-emerald-50 border border-emerald-200 rounded-lg p-5 space-y-2">
    <h3 class="text-sm font-semibold text-emerald-900">üíº Business relevance</h3>
    <ul class="list-disc ml-5 text-sm text-emerald-800 space-y-1">
      <li><strong>Data procurement:</strong> Curate contributor pools with complementary coverage instead of maximising volume from a single vendor.</li>
      <li><strong>Safety budgets:</strong> Quantify correlated failure pockets‚Äîdiversity that doesn‚Äôt break correlations won‚Äôt buy you transcendence.</li>
      <li><strong>Agent routing:</strong> The taxonomy mirrors ensemble and MoE deployments; it tells you which data knobs justify that complexity.</li>
    </ul>
    <div class="bg-white border border-emerald-200 rounded-md p-3 mt-3 space-y-1 text-xs text-emerald-900">
      <p class="font-semibold">Derivative example (apply the paper‚Äôs setup)</p>
      <p class="text-emerald-800">A support-automation team could simulate ‚Äúexperts‚Äù from billing, hardware, and policy teams. By varying how often each team writes about topics inside vs outside its remit, product ops can estimate when a unified LLM will denoise (low overlap errors), when it needs routing metadata (selection), and how many cross-domain playbooks are required before the model generalises rare two-hop escalations.</p>
    </div>
  </div>

  <div class="grid md:grid-cols-3 gap-4">
    <div class="bg-white border border-gray-200 rounded-lg p-3">
      <h5 class="text-sm font-semibold text-gray-900">Key insight</h5>
      <p class="text-xs text-gray-600">Transcendence is not mystical: it emerges precisely when training data supplies the statistical signals (variance, routing bias, compositional structure) the learner can exploit.</p>
    </div>
    <div class="bg-white border border-gray-200 rounded-lg p-3">
      <h5 class="text-sm font-semibold text-gray-900">Method</h5>
      <p class="text-xs text-gray-600">The team derives sufficient conditions for each transcendence mode and instantiates them in a controllable knowledge-graph corpora where GPT-2 is finetuned on templated paragraphs from simulated experts.</p>
    </div>
    <div class="bg-white border border-gray-200 rounded-lg p-3">
      <h5 class="text-sm font-semibold text-gray-900">Implication</h5>
      <p class="text-xs text-gray-600">Architects can decide which diversity lever to fund‚Äîmore experts, domain-aware sampling, or compositional exemplars‚Äîbased on the failure mode they observe.</p>
    </div>
  </div>

  <div class="grid md:grid-cols-2 gap-4">
    <div class="bg-cyan-50 border border-cyan-200 rounded-lg p-4 space-y-2">
      <h3 class="text-sm font-semibold text-cyan-900">Three modes cheat sheet</h3>
      <ul class="list-disc ml-5 text-xs text-cyan-800 space-y-1">
        <li><strong>Skill denoising:</strong> Shared distribution, independent errors. Decoder temperature ‚Üì returns the modal answer.</li>
        <li><strong>Skill selection:</strong> Experts see different parts of the space. Routing probability g(i|x) rises with actual competence.</li>
        <li><strong>Skill generalisation:</strong> Test set sits off-support; model must compose latent representations learned from diverse phrasing.</li>
      </ul>
      <p class="text-[11px] text-cyan-700">The taxonomy extends Zhang et al. (2024) with selection and generalisation grounded in data requirements.</p>
    </div>
    <div class="bg-cyan-50 border border-cyan-200 rounded-lg p-4 space-y-2">
      <h3 class="text-sm font-semibold text-cyan-900">Data diversity levers</h3>
      <ul class="list-disc ml-5 text-xs text-cyan-800 space-y-1">
        <li><strong>Error decorrelation:</strong> More experts with randomised corruptions lower the majority-vote variance.</li>
        <li><strong>Exposure weighting:</strong> Parameter Œ± controls how often specialists talk about their own patch.</li>
        <li><strong>Compositional samples:</strong> Within-expertise two-hop examples act as scaffolding so across-expertise queries become reachable.</li>
      </ul>
      <p class="text-[11px] text-cyan-700">Treat each lever as an experiment knob when auditing instruction-tuning corpora.</p>
    </div>
  </div>

  <div class="bg-white border border-gray-200 rounded-lg p-5 space-y-3">
    <h3 class="text-sm font-semibold text-gray-900">üß™ Experiments & Evidence</h3>
    <ul class="list-disc ml-5 text-sm text-gray-700 space-y-1">
      <li><strong>Denoising:</strong> Finetuning GPT-2 on 10M samples from 100 experts with 20% coverage reaches &gt;80% factual accuracy using greedy decoding, beating any expert.</li>
      <li><strong>Selection:</strong> With coverage 0.1 and Œ± ‚â• 0.95, accuracy approaches 100% once the pool spans enough edge clusters (Fig. 5).</li>
      <li><strong>Generalisation:</strong> Across-expertise two-hop accuracy scales linearly with the count of within-expertise scaffolds; paraphrase diversity lifts it above co-occurrence baselines (Fig. 6).</li>
      <li><strong>Baselines:</strong> Relation-majority and direct-connection heuristics lag far behind the finetuned model on held-out multi-hop queries.</li>
    </ul>
  </div>

  <div class="bg-amber-50 border border-amber-200 rounded-lg p-5 space-y-2">
    <h3 class="text-sm font-semibold text-amber-900">üî≠ For your roadmap</h3>
    <ul class="list-disc ml-5 text-sm text-amber-800 space-y-1">
      <li>Instrument instruction datasets to measure error correlation, topical coverage, and compositional depth.</li>
      <li>Layer routing metadata or provenance tags when you suspect ‚Äúselection‚Äù will help more than raw denoising.</li>
      <li>Invest in synthetic or logged multi-hop exemplars before expecting zero-shot cross-domain reasoning.</li>
      <li>Explore ‚Äúskill discovery‚Äù settings‚Äîan open question the authors flag for future transcendence modes.</li>
    </ul>
  </div>
</div>
