<section class="space-y-5">
  <section class="panel panel-info p-4 space-y-4">
    <div class="flex items-center justify-between gap-4">
      <div class="flex-1 min-w-0">
        <h2 class="text-xl font-semibold text-heading">The impact of AI and digital platforms on the information ecosystem</h2>
        <p class="text-sm panel-muted">Joseph E. Stiglitz, Maxim Ventura-Bolet &bull; NBER Transformative AI Conference (Sep 2025)</p>
      </div>
      <a href="https://conference.nber.org/conf_papers/f227506.pdf" target="_blank" rel="noopener" class="btn-soft text-xs font-semibold flex-shrink-0" data-accent="foundations">
        <span>View paper</span>
        <span aria-hidden="true">↗</span>
      </a>
    </div>
    <p class="text-sm leading-relaxed panel-muted">
      The authors build a model in which news producers choose between truthful investigations and low-cost misinformation while monetising visits through ads and data. Consumers vary in how well they can spot unreliable sources, so the mix of truth versus lies becomes a macro outcome rather than an editorial choice.
    </p>
  </section>

  <section class="panel panel-neutral-soft p-3 space-y-1 text-xs">
    <p class="font-semibold text-heading">Plain-language explainer</p>
    <p class="panel-muted">Imagine a town square where some vendors sell carefully researched facts (expensive to produce) while others sell cheap, eye-catching lies. Customers vary in their ability to tell them apart. AI platforms act like a megaphone that speeds up distribution but also makes lies cheaper to create and harder to distinguish from truth. Without rules requiring transparency and fair compensation for fact-checkers, the square floods with misinformation while honest vendors go out of business — even though the megaphone itself works perfectly.</p>
  </section>

  <section class="panel panel-neutral p-5 space-y-3">
    <header class="flex items-center gap-2">
      <span aria-hidden="true" class="text-lg">🧭</span>
      <h3 class="text-sm font-semibold tracking-wide uppercase text-heading">Executive quick take</h3>
    </header>
    <p class="text-sm leading-relaxed text-body">
      Treat AI newsfeeds as economic shocks to both the cost of lying and the funding of truth. Heterogeneous screening skill means the same shock widens gaps between citizens unless design lifts the floor for the least discerning readers. If accountability and licensing lag, equilibrium tilts toward misinformation even though distribution gets faster. Tie AI deployment to liability, provenance, and revenue sharing before the truth supply contracts.
    </p>
    <ul class="list-disc ml-5 space-y-1 text-sm panel-muted">
      <li><strong>Distribution alone is not the win:</strong> Efficiency gains do not help if producers cannot recover their investigative spend.</li>
      <li><strong>Misinformation is price-sensitive:</strong> When generative tools make lies cheap, their share rises unless screening improves faster.</li>
      <li><strong>Polarisation is endogenous:</strong> Platform design determines whether citizens converge on common facts or split into echo chambers.</li>
    </ul>
  </section>

  <section class="panel panel-success p-5 space-y-3">
    <h3 class="text-sm font-semibold text-heading">&#128188; Business relevance</h3>
    <ul class="list-disc ml-5 space-y-1 text-sm text-body">
      <li><strong>Policy and trust &amp; safety leads:</strong> Quantify how summarisation or chat interfaces displace clicks back to publishers and fund the truth deficit before scaling AI features.</li>
      <li><strong>Platform product managers:</strong> Bake screening effectiveness metrics into launch gates so new AI surfaces do not flood users with plausible-but-false answers.</li>
      <li><strong>Newsroom strategy teams:</strong> Lobby for licensing, data rights, and public-interest subsidies that keep investigative desks solvent as platforms interpose AI layers.</li>
    </ul>
    <div class="panel panel-neutral-soft p-3 mt-3 space-y-1 text-xs">
      <p class="font-semibold text-heading">Derivative example (civic info guardrail playbook)</p>
      <p class="panel-muted">A national election portal negotiates revenue sharing with AI aggregators, requires labelled provenance on generated answers, and funds a pooled fact-checking service that updates the models weekly.</p>
    </div>
  </section>

  <div class="grid md:grid-cols-3 gap-4">
    <div class="panel panel-neutral p-4 space-y-2">
      <h3 class="text-sm font-semibold text-heading">Key insight</h3>
      <p class="text-xs panel-muted">Left unchecked, AI platforms can reduce the equilibrium stock of truthful reporting even if they make distribution faster and cheaper.</p>
    </div>
    <div class="panel panel-neutral p-4 space-y-2">
      <h3 class="text-sm font-semibold text-heading">Method</h3>
      <p class="text-xs panel-muted">A two-sided model of news producers (truthful or deceptive) and consumers with heterogeneous screening ability, augmented with platform parameters that alter costs, traffic, and detection quality.</p>
    </div>
    <div class="panel panel-neutral p-4 space-y-2">
      <h3 class="text-sm font-semibold text-heading">Implications</h3>
      <p class="text-xs panel-muted">Regulation, licensing, and product design choices decide whether AI amplifies a knowledge commons or a misinformation trap.</p>
    </div>
  </div>

  <div class="grid md:grid-cols-2 gap-4">
    <div class="panel panel-info p-4 space-y-2">
      <h3 class="text-sm font-semibold text-heading">Four channels to stress test</h3>
      <p class="text-xs panel-muted">Each lever from the paper maps to a product or policy decision your team controls.</p>
      <ul class="list-disc ml-4 space-y-1 text-xs panel-muted">
        <li><strong>Processing &amp; transmission:</strong> AI summarisation improves speed but must preserve provenance.</li>
        <li><strong>Producer monetisation:</strong> Traffic leakage to platforms can bankrupt investigative desks.</li>
        <li><strong>Misinformation cost:</strong> Generators drive marginal costs of lies toward zero.</li>
        <li><strong>Consumer screening:</strong> Assistive AI can help or hurt depending on how prompts, cues, and defaults are designed.</li>
      </ul>
    </div>
    <div class="panel panel-info p-4 space-y-2">
      <h3 class="text-sm font-semibold text-heading">&#128737; What guardrails change</h3>
      <p class="text-xs panel-muted">Accountability norms invert the payoff matrix for both publishers and platforms, and even seemingly neutral AI intermediaries that flatten everyone's feed only delay divergence unless those norms stick.</p>
      <ul class="list-disc ml-4 space-y-1 text-xs panel-muted">
        <li>Liability or IP enforcement raises the effective cost of distributing false content.</li>
        <li>Licensing and public funding top up truth supply when ads/data revenue fall.</li>
        <li>Transparency mandates improve consumer filtering and cool polarisation.</li>
      </ul>
    </div>
  </div>

  <section class="panel panel-neutral p-5 space-y-3">
    <h3 class="text-sm font-semibold text-heading">&#128202; Evidence base</h3>
    <ul class="list-disc ml-5 space-y-1 text-sm panel-muted">
      <li>Defines equilibrium producer profits under platform revenue shares (&#969;), truth valuation (v<sub>T</sub>, v<sub>U</sub>), and screening skill (&#952;).</li>
      <li>Shows that when AI lowers misinformation costs faster than it improves screening, the share of lies rises and truthful output shrinks.</li>
      <li>Demonstrates multiple Nash equilibria where platform policy selects the mix of truth versus misinformation.</li>
      <li>Analyses regulatory tools &mdash; accountability, moderation, IP protection &mdash; that restore a high-truth steady state.</li>
    </ul>
  </section>

  <section class="panel panel-warning p-5 space-y-2">
    <h3 class="text-sm font-semibold text-heading">&#128678; Forward-looking roadmap</h3>
    <ul class="list-disc ml-5 space-y-1 text-sm text-body">
      <li>Measure how AI summaries affect publisher visit depth and investigate reimbursement models before launch.</li>
      <li>Test consumer co-pilots that highlight source reliability scores instead of drafting definitive answers.</li>
      <li>Codify liability triggers for repeated misinformation so platform economics internalise the social cost.</li>
      <li>Pursue public-interest data licensing or subsidies that keep investigative newsrooms solvent.</li>
    </ul>
  </section>
</section>












