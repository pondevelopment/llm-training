<section class="space-y-5">
  <!-- Paper header -->
  <section class="panel panel-info p-4 space-y-4">
    <div class="flex items-center justify-between gap-4">
      <div class="flex-1 min-w-0">
        <h2 class="text-xl font-semibold text-heading">Performance or Principle: Resistance to Artificial Intelligence in the U.S. Labor Market</h2>
        <p class="text-sm panel-muted">Simon Friis, James W. Riley â€¢ Harvard Business School (2025)</p>
      </div>
      <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5560401" target="_blank" rel="noopener" class="btn-soft text-xs font-semibold flex-shrink-0" data-accent="foundations">
        <span>View paper</span>
        <span aria-hidden="true">â†—</span>
      </a>
    </div>
    <p class="text-sm leading-relaxed panel-muted">
      Large-scale U.S. survey (N=23,570 occupation ratings across 940 occupations) reveals that Americans are surprisingly willing to automate most jobsâ€”supporting automation of 30% of occupations at current AI capabilities, rising to 58% when AI outperforms humans at lower cost. However, 12% of occupations face categorical moral objection regardless of AI capability, including caregiving, therapy, and spiritual leadership. The study disentangles performance-based resistance (fades as AI improves) from principle-based objections (permanent moral boundaries), revealing a "moral economy of work" where society shields certain roles based on beliefs about dignity and meaning. Occupations facing resistance tend to provide higher wages and disproportionately employ White and female workers, creating complex inequality implications.
    </p>
    <div class="panel panel-neutral-soft p-3 space-y-1 text-xs">
      <p class="font-semibold text-heading">Plain-language explainer</p>
      <p class="panel-muted">When launching AI products, you'll face two completely different types of resistance. For most jobs (88%), customers resist because your AI isn't demonstrably better yetâ€”overcome this by proving superior performance and lower cost. But for 12% of jobs, customers resist on moral grounds regardless of how good your AI is. Deploy AI for financial analysis? You'll face performance skepticism you can beat with benchmarks. Deploy AI for therapy or childcare? You've hit a moral wall that capability improvements can't penetrate. Knowing which type you're facing determines whether you need better tech or different positioning.</p>
    </div>
  </section>

  <!-- Executive quick take -->
  <section class="panel panel-neutral p-5 space-y-3">
    <header class="flex items-center gap-2">
      <span aria-hidden="true" class="text-lg">ðŸ§­</span>
      <h3 class="text-sm font-semibold tracking-wide uppercase text-heading">Executive quick take</h3>
    </header>
    <p class="text-sm leading-relaxed text-body">
      Public resistance to AI automation divides into two fundamentally different types: temporary skepticism about AI performance (88% of occupations) and permanent moral boundaries (12% of occupations). For most jobs, demonstrating superior AI capability at lower cost is sufficient to gain public support. However, roles involving caregiving, emotional support, and spiritual guidance face categorical rejection regardless of technical performance. This creates a governance paradox: the occupations most protected from automation tend to be higher-paying and disproportionately employ White workers, potentially reinforcing economic and racial inequality even as it protects female-dominated care professions.
    </p>
    <ul class="list-disc ml-5 space-y-1 text-sm panel-muted">
      <li><strong>Performance threshold unlocks most automation:</strong> Support nearly doubles from 30% to 58% of occupations when AI is described as outperforming humans at lower costâ€”resistance is pragmatic, not ideological, for majority of jobs</li>
      <li><strong>Moral boundaries are non-negotiable:</strong> 12% of occupations (caregiving, therapy, spiritual leadership) remain categorically off-limits; describing AI as superior actually increases moral repugnance for these roles</li>
      <li><strong>Inequality implications cut both ways:</strong> Protected occupations tend to have higher wages and disproportionately employ White and female workersâ€”creating trade-offs between economic fairness and gender equity</li>
    </ul>
  </section>

  <!-- Business relevance -->
  <section class="panel panel-success p-5 space-y-3">
    <header class="flex items-center gap-2">
      <span aria-hidden="true" class="text-lg">ðŸ’¼</span>
      <h3 class="text-sm font-semibold tracking-wide uppercase text-heading">Business relevance</h3>
    </header>
    <ul class="list-disc ml-5 space-y-2 text-sm text-body">
      <li><strong>AI Product Teams:</strong> For performance-sensitive occupations (88%), focus go-to-market messaging on capability benchmarks and cost advantages; for morally-protected roles (12%), capability claims may backfireâ€”emphasize "augmentation" and "human oversight" instead</li>
      <li><strong>Healthcare & EdTech Executives:</strong> Caregiving and teaching roles face moral resistance even when AI demonstrates superior diagnostic or instructional capability; position products as decision support tools, never as human replacements</li>
      <li><strong>Workforce Planning Leaders:</strong> Public support for automation doesn't equal employee acceptance; the 58% support ceiling with superior AI means 42% of occupations still face resistanceâ€”plan change management accordingly</li>
      <li><strong>Policy & Ethics Teams:</strong> Moral boundaries correlate with demographics (higher-wage, Whiter, more female occupations protected); anticipate regulatory scrutiny around whether AI deployment exacerbates existing inequalities</li>
    </ul>
    <div class="panel panel-neutral-soft p-4 space-y-2">
      <h4 class="text-sm font-semibold text-heading">Derivative example: Pre-launch resistance mapping</h4>
      <p class="text-xs leading-relaxed text-body">
        Before deploying AI in a new domain, run a two-phase assessment: (1) <strong>Performance framing test</strong> â€” survey target users with "AI performs as well as humans" vs "AI outperforms humans at lower cost" scenarios and measure support delta; if support jumps â‰¥20%, resistance is performance-based and you can overcome it with capability demos. (2) <strong>Moral framing test</strong> â€” add a third condition describing AI as "highly capable but emotionally detached" and measure sentiment; if support drops or moral repugnance language emerges ("wrong," "shouldn't happen"), you've hit a principle-based barrier requiring augmentation positioning, not replacement rhetoric. This two-question framework predicts whether your adoption bottleneck is technical proof or moral framing.
      </p>
    </div>
  </section>

  <!-- Supporting callouts -->
  <section class="grid md:grid-cols-2 gap-4">
    <div class="panel panel-info p-4 space-y-2">
      <h4 class="text-sm font-semibold text-heading">Performance-based vs Principle-based resistance</h4>
      <p class="text-xs leading-relaxed panel-muted">
        <strong>Performance-based resistance:</strong> "AI isn't good enough yet"â€”fades as capabilities improve. Seen in 88% of occupations (software development, legal research, financial analysis). Respondents cite concerns about accuracy, reliability, or cost-effectiveness that can be addressed through better technology.
      </p>
      <p class="text-xs leading-relaxed panel-muted">
        <strong>Principle-based resistance:</strong> "AI should never do this"â€”persists regardless of capability. Seen in 12% of occupations (therapy, childcare, hospice care, religious leadership). Respondents use moral language ("wrong," "repugnant," "dehumanizing") that doesn't respond to performance improvements.
      </p>
    </div>
    <div class="panel panel-info p-4 space-y-2">
      <h4 class="text-sm font-semibold text-heading">The moral economy of work</h4>
      <p class="text-xs leading-relaxed panel-muted">
        The study identifies a "moral economy of work"â€”a shared social understanding of which occupations require human presence not for technical reasons but to preserve dignity, meaning, and care. This boundary isn't about what AI <em>can</em> do but what it <em>should</em> do. Occupations behind this boundary involve: (1) care for vulnerable populations (children, elderly, terminally ill), (2) emotional labor requiring empathy and presence, (3) spiritual or existential guidance, (4) roles where automation itself causes harm regardless of performance (e.g., "AI therapist" feels degrading even if effective).
      </p>
    </div>
  </section>

  <!-- Key insight / Method / Implication -->
  <section class="grid md:grid-cols-3 gap-4">
    <div class="panel panel-neutral p-4 space-y-2">
      <h4 class="text-sm font-semibold text-heading">ðŸ’¡ Key insight</h4>
      <p class="text-xs leading-relaxed text-body">
        Resistance to AI automation is not monolithic. For most occupations (88%), resistance is temporary and performance-basedâ€”overcome it by demonstrating superior capability and cost. For a small but critical subset (12%), resistance is permanent and principle-basedâ€”these occupations have crossed into moral territory where technical improvement is irrelevant. The key strategic question is: "Will better AI change minds, or will it entrench moral objections?"
      </p>
    </div>
    <div class="panel panel-neutral p-4 space-y-2">
      <h4 class="text-sm font-semibold text-heading">ðŸ”¬ Method</h4>
      <p class="text-xs leading-relaxed text-body">
        Large-scale survey of 23,570 U.S. adults rating 940 occupations, quota-matched to census demographics (age, gender, race, income, education). Each respondent evaluated 25 randomly assigned occupations under three conditions: (1) current AI capabilities, (2) AI outperforming humans at lower cost, (3) open-ended rationale for resistance. Statistical modeling identified performance-sensitive occupations (support increased with capability framing) vs principle-resistant occupations (support remained flat or decreased). Demographic analysis linked protected occupations to wage data and workforce composition.
      </p>
    </div>
    <div class="panel panel-neutral p-4 space-y-2">
      <h4 class="text-sm font-semibold text-heading">âš¡ Implication</h4>
      <p class="text-xs leading-relaxed text-body">
        AI adoption strategies must fork: for performance-sensitive roles, invest in benchmarks, transparency, and cost demonstrations to overcome pragmatic resistance. For morally-protected roles, abandon replacement framing entirelyâ€”position AI as augmentation, oversight, or administrative support that preserves human primacy. Ignoring this distinction risks public backlash, regulatory intervention, and market rejection even for technically superior AI. The moral economy of work is non-negotiable; work within it or face categorical resistance.
      </p>
    </div>
  </section>

  <!-- Evidence -->
  <section class="panel panel-neutral p-5 space-y-3">
    <header class="flex items-center gap-2">
      <span aria-hidden="true" class="text-lg">ðŸ§ª</span>
      <h3 class="text-sm font-semibold tracking-wide uppercase text-heading">Evidence</h3>
    </header>
    <ul class="list-disc ml-5 space-y-2 text-sm panel-muted">
      <li><strong>Support threshold at current capabilities:</strong> 30% of occupations supported for automation with current AI performance; rises to 58% when AI described as outperforming humans at lower costâ€”showing 88% of occupations face performance-based resistance</li>
      <li><strong>Augmentation vs automation gap:</strong> 94.4% of occupations supported for AI augmentation (assisting humans) under current capabilities, rising marginally to 95.6% under advanced AIâ€”much higher than automation support, suggesting concerns center on displacement rather than collaboration</li>
      <li><strong>Categorical rejection of automation:</strong> For the 12% of morally repugnant occupations (clergy, childcare workers, therapists, funeral directors), automation support is 0% even when AI outperforms humansâ€”resistance is absolute and unresponsive to capability improvements</li>
      <li><strong>Employment impact:</strong> Estimated 17.3-21.9 million U.S. workers (11.5-14.6% of workforce) are in occupations where AI use is considered morally repugnant, representing a substantial portion of the labor market shielded by moral boundaries</li>
      <li><strong>Demographic patterns:</strong> Occupations with higher wages, higher proportions of women, and higher proportions of White workers show significantly higher moral repugnance scores (OLS regression across 940 occupations)</li>
      <li><strong>Performance-sensitive examples:</strong> File clerks, data entry keyers, and cashiers show near-universal support for augmentation (99%) and high automation acceptance (61% â†’ 93%)â€”resistance fades as AI improves</li>
    </ul>
  </section>

  <!-- Roadmap -->
  <section class="panel panel-warning p-5 space-y-3">
    <header class="flex items-center gap-2">
      <span aria-hidden="true" class="text-lg">ðŸ”­</span>
      <h3 class="text-sm font-semibold tracking-wide uppercase text-heading">For your roadmap</h3>
    </header>
    <p class="text-sm leading-relaxed text-body">
      Use the performance vs principle framework to anticipate resistance before deployment. For any new AI application, test whether resistance is temporary (performance-based) or permanent (principle-based) using the two-phase survey approach in the derivative example above. This determines whether your go-to-market strategy should emphasize capability benchmarks or human augmentation framing.
    </p>
    <ul class="list-disc ml-5 space-y-1 text-sm text-body">
      <li>Map your target occupations to performance-sensitive (88%) vs morally-protected (12%) categories based on care intensity, emotional labor, and vulnerability of served population</li>
      <li>For performance-sensitive roles: invest in public benchmarks, transparency reports, and cost-benefit analyses; resistance will fade as you demonstrate superiority</li>
      <li>For morally-protected roles: design hybrid solutions that preserve human touch in morally sensitive tasksâ€”reframe AI as augmentation tool rather than replacement (94% augmentation support vs 0% automation support)</li>
      <li>Anticipate policy implications: eldercare, therapy, and spiritual counsel face regulatory scrutiny similar to GMOs or stem cell research; prepare for licensing debates and liability frameworks</li>
      <li>Monitor demographic patternsâ€”protected occupations affect 17-22 million workers disproportionately White/female, creating inequality trade-offs that invite regulatory and public attention</li>
      <li>Test adoption messaging early: if capability claims trigger moral language ("wrong," "shouldn't"), you've crossed into principle territory and must pivot from performance benchmarks to augmentation framing</li>
    </ul>
  </section>
</section>
