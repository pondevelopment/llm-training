<section class="space-y-5">
  <section class="panel panel-info p-4 space-y-4">
    <div class="flex items-center justify-between gap-4">
      <div class="flex-1 min-w-0">
        <h2 class="text-xl font-semibold text-heading">Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers</h2>
        <p class="text-sm panel-muted">Tuhin Chakrabarty, Jane C. Ginsburg, Paramveer Dhillon • arXiv cs.CL (2025)</p>
      </div>
      <a href="https://arxiv.org/abs/2510.13939" target="_blank" rel="noopener" class="btn-soft text-xs font-semibold flex-shrink-0" data-accent="foundations">
        <span>View paper</span>
        <span aria-hidden="true">↗</span>
      </a>
    </div>
    <p class="text-sm leading-relaxed panel-muted">
      A preregistered study comparing MFA-trained expert writers with frontier AI models reveals a dramatic reversal: while in-context prompting produces text strongly disfavored by experts, fine-tuning on authors' complete copyrighted works generates outputs that experts prefer for both stylistic fidelity (OR=8.16) and writing quality (OR=1.87). At \$81 median cost per author—a 99.7% reduction versus professional writer compensation—the findings provide empirical evidence directly relevant to copyright's fourth fair-use factor: market impact of derivative AI works.
    </p>
    <div class="panel panel-neutral-soft p-3 space-y-1 text-xs">
      <p class="font-semibold text-heading">Plain-language explainer</p>
      <p class="panel-muted">Imagine hiring a ghostwriter to mimic Stephen King's style. A novice who read a few King books might produce awkward pastiches that fans immediately reject. But a skilled writer who studied King's entire catalog could capture his voice so well that even literary critics prefer it to King's own work. This study shows AI follows the same pattern: basic prompting fails badly, but training on an author's complete works produces writing that experts and readers actually prefer to human-written text—raising urgent questions about copyright protection when AI can economically replace professional writers.</p>
    </div>
  </section>

  <section class="panel panel-neutral p-5 space-y-3">
    <header class="flex items-center gap-2">
      <span aria-hidden="true" class="text-lg">🧭</span>
      <h3 class="text-sm font-semibold tracking-wide uppercase text-heading">Executive quick take</h3>
    </header>
    <p class="text-sm leading-relaxed text-body">
      Fine-tuning AI on copyrighted books completely reverses expert preferences: outputs shift from strongly disfavored (OR=0.16) to strongly preferred (OR=8.16) compared to human writers. This happens because fine-tuning eliminates detectable AI quirks like cliche density while capturing authentic stylistic patterns. At \$81 per author versus typical professional fees, the economic disruption is immediate—and the legal implications for copyright's "market harm" fair-use factor are profound. Detection is nearly impossible (3% vs 97% for in-context), making enforcement unviable.
    </p>
    <ul class="list-disc ml-5 space-y-1 text-sm panel-muted">
      <li><strong>Preference reversal mechanism:</strong> In-context prompting generates detectable AI quirks (cliche overuse, formulaic patterns) that experts penalize. Fine-tuning on complete works eliminates these artifacts while capturing authentic voice, flipping expert preference from strongly negative (OR=0.16) to strongly positive (OR=8.16)</li>
      <li><strong>Economic disruption:</strong> Median cost of \$81 per author for fine-tuning + inference represents 99.7% reduction versus professional writer compensation. This enables non-verbatim derivative works at scale, directly impacting the commercial market for original works</li>
      <li><strong>Detection failure:</strong> Fine-tuned outputs evade AI detection (3% flagged) versus in-context prompting (97% flagged). Combined with reader preference for AI text, traditional content moderation and copyright enforcement become impractical</li>
    </ul>
  </section>

  <!-- Business relevance -->
  <section class="panel panel-success p-5 space-y-3">
    <h3 class="text-sm font-semibold text-heading">💼 Business relevance</h3>
    <ul class="list-disc ml-5 space-y-1 text-sm text-body">
      <li><strong>Publishing executives and rights holders:</strong> Fine-tuning on author catalogs produces outputs readers prefer to human-written text. With detection nearly impossible (3% accuracy) and 99.7% cost savings, economic substitution of original works becomes viable. Evaluate whether current licensing models capture this derivative market or require new protection mechanisms</li>
      <li><strong>Legal and IP strategy teams:</strong> Study provides empirical evidence for copyright's fourth fair-use factor ("market harm"). Mediation analysis shows fine-tuning eliminates stylistic quirks that expose in-context outputs, creating authentic-seeming derivatives. Courts now have quantified data on preference shifts (OR=8.16) and cost differentials when assessing transformative use claims</li>
      <li><strong>Content agencies and creative services:</strong> Reader preference for AI outputs (when fine-tuned) combined with 99.7% cost reduction creates immediate competitive pressure. Agencies must decide whether to adopt fine-tuned models for client work, invest in hybrid workflows (AI generation + human editing), or emphasize human creativity aspects AI cannot replicate</li>
      <li><strong>AI researchers and ethicists:</strong> Results show that detection-based content moderation fails for fine-tuned models (3% vs 97% for in-context). Policy interventions must shift from technical detection to licensing frameworks, attribution requirements, and economic compensation models rather than hoping to identify AI-generated text</li>
    </ul>
    <div class="panel panel-neutral-soft p-3 mt-3 space-y-2">
      <h4 class="text-sm font-semibold text-heading">Derivative example: B2B content agency scales production with AI fine-tuning</h4>
      <p class="text-xs text-body">
        <strong>Business challenge:</strong> Velocity Content Studio (Chicago) produces whitepapers for 40 enterprise tech clients at \$15K/asset (\$600K ARR). VP Sales reports \$345K pipeline blocked by content production capacity. Solution: Fine-tune models on each client's existing content library to generate brand-matched assets. Key questions: Will clients approve AI-assisted thought leadership? Can quality maintain lead-gen performance (47 MQLs/asset baseline)? What contractual disclosures required?
      </p>
      <p class="text-xs text-body">
        <strong>HAL-style evaluation protocol:</strong> Q2 2024 pilot across 6 clients (35% of ARR): Fine-tune GPT-4 on each client's 3-5 year content library (\$300-500/client). Generate sample whitepapers (12K words) using brand style guides. Blind evaluation by 20 B2B marketing experts (CMI members, Gartner analysts) and 80 buyer personas (IT Directors, CISOs, CFOs via LinkedIn). Metrics: (1) Brand voice authenticity, (2) Persuasiveness, (3) AI detection accuracy. Budget: \$20K (\$12K fine-tuning + \$8K evaluators). Success criteria: AI scores within 15% of human baseline, detection &lt;20%. Timeline: 8-week validation, 2-week review, Q3 rollout decision.
      </p>
      <p class="text-xs text-body">
        <strong>Business impact:</strong> July 2024 results: Experts prefer AI content for 4/6 clients (OR=4.2); buyer personas show stronger preference (OR=6.8). Detection rate: 8% (barely above chance). August 2024: Executive team approves rollout. <strong>Strategy:</strong> (1) Launch "Content Amplification Package" for top 10 clients—3 human + 3 AI-assisted assets annually (50% capacity boost, 30% price premium). (2) Hybrid workflow: 3-week cycle vs 8-week traditional. (3) <strong>Revenue:</strong> +\$150K incremental deliverables, -\$50K costs → +\$100K net ARR (17% growth). (4) <strong>Pipeline:</strong> Convert 8/23 blocked deals using "faster time-to-content" pitch → +\$120K ARR (Q4 2024). (5) <strong>Retention:</strong> NPS +12 points. (6) <strong>Positioning:</strong> "AI-Augmented Content Studio" differentiator; SOWs include AI disclosure. First-year ROI: 417%. <strong>2025 plan:</strong> 25 clients, hire 2 AI engineers, target \$1.2M ARR (+100% YoY), 60% margins vs 45% traditional.
      </p>
    </div>
  </section>

  <!-- Key insight / Method / Implication -->
  <section class="grid grid-cols-1 md:grid-cols-3 gap-4">
    <div class="panel panel-neutral p-4 space-y-2">
      <h3 class="text-sm font-semibold text-heading">Key insight</h3>
      <p class="text-xs text-body">
        Fine-tuning on complete author catalogs completely reverses expert judgment compared to in-context prompting: stylistic fidelity shifts from strongly disfavored (OR=0.16) to strongly preferred (OR=8.16). Mediation analysis reveals this occurs because fine-tuning eliminates detectable AI quirks (cliche density, formulaic phrasing) that penalize in-context outputs while capturing authentic voice patterns. Reader preference for AI-generated text becomes the norm, not the exception.
      </p>
    </div>
    <div class="panel panel-neutral p-4 space-y-2">
      <h3 class="text-sm font-semibold text-heading">Method</h3>
      <p class="text-xs text-body">
        Preregistered study with 159 expert and lay readers conducting blind pairwise evaluations. Three frontier models (ChatGPT, Claude, Gemini) compared against MFA-trained expert writers across 50 award-winning authors' styles. In-context prompting provides basic style examples; fine-tuning uses each author's complete published works. Mediation analysis isolates stylistic quirks (cliche density, formulaic markers) explaining preference shifts. AI detectors test distinguishability of outputs.
      </p>
    </div>
    <div class="panel panel-neutral p-4 space-y-2">
      <h3 class="text-sm font-semibold text-heading">Implication</h3>
      <p class="text-xs text-body">
        Economic substitution of professional writers becomes viable: \$81 median cost per author (99.7% reduction) combined with reader preference for AI outputs creates immediate market pressure. Detection-based content moderation fails (3% accuracy for fine-tuned outputs). Copyright doctrine's fourth fair-use factor—"effect upon the potential market"—now has quantified evidence that fine-tuned AI can replace commercial demand for original works. Legal frameworks must adapt beyond detection to licensing and attribution.
      </p>
    </div>
  </section>

  <!-- Evidence -->
  <section class="panel panel-neutral p-5 space-y-3">
    <h3 class="text-sm font-semibold text-heading">🧪 Evidence</h3>
    <ul class="list-disc ml-5 space-y-1 text-sm text-body">
      <li><strong>Preference reversal quantified:</strong> In-context prompting yields expert odds ratios of 0.16 (stylistic fidelity, p&lt;10⁻⁸) and 0.13 (writing quality, p&lt;10⁻⁷)—strong rejection. Fine-tuning flips these to 8.16 (stylistic fidelity, p&lt;10⁻¹³) and 1.87 (writing quality, p=0.010)—strong preference. Lay readers show similar directional shifts with even larger effect sizes</li>
      <li><strong>Detection evasion:</strong> Best AI detectors flag fine-tuned outputs at 3% rate versus 97% for in-context prompting. Fine-tuning eliminates detectable quirks (cliche density, formulaic patterns) through mediation analysis, making outputs indistinguishable from human writing to both readers and automated systems</li>
      <li><strong>Economic displacement:</strong> Median fine-tuning and inference cost of \$81 per author represents 99.7% reduction compared to typical professional writer compensation. Study does not account for human editing required to transform raw output into publishable prose, but cost differential remains orders of magnitude even with post-processing</li>
      <li><strong>Generalization across styles:</strong> Effects hold across 50 award-winning authors spanning diverse genres and stylistic approaches. Neither author reputation nor genre complexity significantly moderates the preference reversal, suggesting broad applicability to literary production beyond tested sample</li>
      <li><strong>Copyright fair-use implications:</strong> Findings provide empirical evidence directly addressing copyright's fourth factor ("effect upon the potential market or value"). When readers prefer AI-generated derivatives to original works at 0.3% of production cost, commercial market substitution becomes quantifiable rather than speculative</li>
    </ul>
  </section>

  <!-- Roadmap -->
  <section class="panel panel-warning p-5 space-y-3">
    <h3 class="text-sm font-semibold text-heading">🔭 For your roadmap</h3>
    <p class="text-sm text-body">
      The combination of reader preference for AI outputs, near-total detection evasion, and 99.7% cost reduction creates immediate strategic decisions for content organizations, legal teams, and platform operators. Focus your planning on economic adaptation and policy frameworks rather than technical detection, which the study shows is now impractical.
    </p>
    <ul class="list-disc ml-5 space-y-1 text-sm text-body">
      <li><strong>Audit content licensing frameworks:</strong> Review contracts with authors, content creators, and rights holders for derivative-works clauses covering AI fine-tuning. Current agreements typically address human ghostwriting but not model training. Add explicit terms governing: (1) whether catalog can be used for fine-tuning, (2) revenue sharing for AI-generated derivatives, (3) attribution requirements, (4) quality control processes for AI-augmented output</li>
      <li><strong>Test reader acceptance in your domain:</strong> Replicate study methodology for your content vertical. Commission blind pairwise evaluations comparing fine-tuned AI outputs to human-written content across key authors/creators. Measure: stylistic fidelity, perceived quality, engagement metrics (time-on-page, completion rates). Segment by expert vs lay audiences to identify where AI substitution is viable versus where human authorship retains premium</li>
      <li><strong>Develop hybrid editorial workflows:</strong> Given reader preference for fine-tuned outputs but need for human editorial oversight, design processes where AI generates drafts and human editors refine. Measure: time savings, quality degradation (if any), cost per finished piece. Determine optimal human-in-the-loop touch-points: outline review, draft editing, final polish, or full rewrites</li>
      <li><strong>Engage legal counsel on fair-use posture:</strong> Study provides quantified market-harm evidence courts will cite in copyright litigation. Work with IP lawyers to assess: (1) whether your fine-tuning practices qualify as transformative use, (2) how to document non-substitution if you claim complementary rather than derivative market, (3) whether proactive licensing mitigates litigation risk versus waiting for case law to develop</li>
      <li><strong>Shift from detection to attribution:</strong> Detection-based content moderation fails for fine-tuned outputs (3% accuracy). Explore alternative governance: (1) require AI-generated content disclosures regardless of detectability, (2) implement watermarking at generation time rather than post-hoc detection, (3) use economic provenance (license verification) instead of technical fingerprinting. Update content policies to assume undetectable AI rather than relying on detection tools</li>
    </ul>
  </section>

  <!-- Option 2: With nested subsections (like P03) -->
  <!-- Uncomment and adapt if you need to expand on specific topics:
  <section class="panel panel-warning p-5 space-y-3">
    <h3 class="text-sm font-semibold text-heading">🔭 For your roadmap</h3>
    <p class="text-sm text-body">[Opening context paragraph explaining the roadmap focus]</p>
    
    <div class="panel panel-info p-4 space-y-2">
      <h4 class="text-sm font-semibold text-heading">[Subsection title]</h4>
      <p class="text-xs text-body leading-relaxed">[2-4 paragraphs of detailed guidance]</p>
      <ul class="list-disc ml-4 text-xs text-body space-y-1">
        <li>[Specific point 1]</li>
        <li>[Specific point 2]</li>
      </ul>
    </div>
    
    <ul class="list-disc ml-5 space-y-1 text-sm text-body">
      <li>[Actionable item 1]</li>
      <li>[Actionable item 2]</li>
      <li>[Actionable item 3]</li>
    </ul>
  </section>
  -->
</section>
