<div class="space-y-6">
  <!-- Model Configuration -->
  <div class="question-card space-y-2">
    <label for="q4-model-size" class="block text-sm font-medium text-heading">&#x1F3D7;&#xFE0F; Select model size to fine-tune</label>
    <select id="q4-model-size" class="w-full px-3 py-2 border border-subtle rounded-md focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:border-indigo-500 bg-card text-body shadow-sm">
      <option value="small" selected>Small model (1.3B parameters)</option>
      <option value="medium">Medium model (7B parameters)</option>
      <option value="large">Large model (13B parameters)</option>
      <option value="xl">XL model (70B parameters)</option>
    </select>
    <p class="small-caption text-muted">&#x1F446; Compare how memory requirements scale with size.</p>
  </div>

  <!-- Fine-tuning Method Selection -->
  <div class="question-card space-y-4">
    <label class="block text-sm font-medium text-heading">&#x1F3AF; Choose fine-tuning method</label>
    <div class="grid grid-cols-1 md:grid-cols-3 gap-3">
      <label class="question-strategy" data-tone="emerald">
        <input type="radio" name="q4-method" value="full" class="sr-only">
        <div class="stacked-card space-y-2">
          <div class="flex items-center justify-between gap-2">
            <span class="font-medium text-heading">Full fine-tuning</span>
            <span class="chip chip-success text-xs">Maximum flexibility</span>
          </div>
          <p class="small-caption text-muted">Updates every parameter in the base model.</p>
          <p class="small-caption text-muted">Best when you must change core behaviour.</p>
        </div>
      </label>

      <label class="question-strategy" data-tone="purple">
        <input type="radio" name="q4-method" value="lora" class="sr-only" checked>
        <div class="stacked-card space-y-2">
          <div class="flex items-center justify-between gap-2">
            <span class="font-medium text-heading">LoRA</span>
            <span class="chip chip-accent text-xs">Adapter based</span>
          </div>
          <p class="small-caption text-muted">Freezes the foundation weights and learns low-rank adapters.</p>
          <p class="small-caption text-muted">Strong baseline when you need rapid experiments.</p>
        </div>
      </label>

      <label class="question-strategy" data-tone="amber">
        <input type="radio" name="q4-method" value="qlora" class="sr-only">
        <div class="stacked-card space-y-2">
          <div class="flex items-center justify-between gap-2">
            <span class="font-medium text-heading">QLoRA</span>
            <span class="chip chip-warning text-xs">Ultra efficient</span>
          </div>
          <p class="small-caption text-muted">Pairs LoRA adapters with a 4-bit quantized base model.</p>
          <p class="small-caption text-muted">Ideal for large models on constrained hardware.</p>
        </div>
      </label>
    </div>
    <div class="grid grid-cols-1 md:grid-cols-2 gap-3">
      <div class="space-y-2">
        <label for="q4-rank" class="block text-xs font-medium text-secondary">Adapter rank (r)</label>
        <select id="q4-rank" class="w-full px-2 py-1.5 border border-subtle rounded-md text-sm focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:border-indigo-500 bg-card text-body">
          <option value="4">r = 4 (compact)</option>
          <option value="8" selected>r = 8 (balanced)</option>
          <option value="16">r = 16</option>
          <option value="32">r = 32 (large)</option>
        </select>
      </div>
      <div id="q4-quant-wrapper" class="space-y-2">
        <label for="q4-quant" class="block text-xs font-medium text-secondary">Quantization (base model)</label>
        <select id="q4-quant" class="w-full px-2 py-1.5 border border-subtle rounded-md text-sm focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:border-indigo-500 bg-card text-body">
          <option value="4" selected>4-bit NF4 (QLoRA)</option>
          <option value="8">8-bit (LLM.int8)</option>
          <option value="16">16-bit (no quantization)</option>
        </select>
        <p id="q4-quant-note" class="small-caption text-muted">Only applies when QLoRA is selected.</p>
      </div>
    </div>
  </div>

  <!-- Quick Examples -->
  <div class="question-card flex flex-wrap items-center gap-2">
    <span class="text-sm font-medium text-heading">&#x1F4A1; Quick examples:</span>
    <button id="q4-example-btn" class="btn-soft text-xs">Try: Consumer GPU scenario</button>
  </div>

  <!-- Visualization -->
  <div class="question-card space-y-4">
    <div class="flex items-center justify-between gap-3">
      <h4 class="font-medium text-heading">&#x1F3A8; Parameter visualization</h4>
      <div id="q4-method-indicator" class="chip chip-info text-xs">LoRA method</div>
    </div>
    <div class="grid md:grid-cols-2 gap-6">
      <div class="space-y-3">
        <h5 class="text-sm font-medium text-heading">Weight matrix structure</h5>
        <div id="q4-matrix-visualization" class="border border-subtle rounded-lg p-4 h-48 flex items-center justify-center bg-subtle">
          <div id="q4-matrix-display" class="grid gap-1"></div>
        </div>
        <div id="q4-matrix-legend" class="flex flex-wrap gap-3 text-xs text-secondary">
          <span class="legend-dot legend-dot-muted">Frozen parameters</span>
          <span class="legend-dot legend-dot-accent">Trainable adapters</span>
          <span class="legend-dot legend-dot-warning">Quantized weights</span>
        </div>
      </div>
      <div class="space-y-3">
        <div class="panel panel-info p-3 space-y-2">
          <h6 class="font-medium text-heading">&#x1F5A5;&#xFE0F; Memory requirements</h6>
          <div class="text-2xl font-bold text-heading" id="q4-memory-value">~50 GB</div>
          <div class="context-meter" data-tone="sky">
            <div id="q4-memory-bar" class="context-meter-fill" style="width: 20%"></div>
          </div>
          <p class="small-caption text-muted" id="q4-memory-note">GPU memory usage</p>
        </div>
        <div class="panel panel-success p-3 space-y-2">
          <h6 class="font-medium text-heading">&#x26A1; Training speed</h6>
          <div class="text-lg font-bold text-heading" id="q4-speed-value">3x faster</div>
          <div class="context-meter" data-tone="emerald">
            <div id="q4-speed-bar" class="context-meter-fill" style="width: 75%"></div>
          </div>
          <p class="small-caption text-muted" id="q4-speed-note">Versus full fine-tuning</p>
        </div>
        <div class="panel panel-accent p-3 space-y-2">
          <h6 class="font-medium text-heading">&#x1F4AF; Parameter efficiency</h6>
          <div class="text-lg font-bold text-heading" id="q4-efficiency-value">99.6% reduction</div>
          <div class="context-meter" data-tone="purple">
            <div id="q4-efficiency-bar" class="context-meter-fill" style="width: 95%"></div>
          </div>
          <p class="small-caption text-muted" id="q4-efficiency-note">Trainable parameters</p>
        </div>
      </div>
    </div>
  </div>

  <!-- Quantization Explorer -->
  <div class="question-card space-y-4">
    <div class="flex items-center justify-between gap-3">
      <h4 class="font-medium text-heading">&#x1F9E9; Quantization explorer (4-bit vs 16-bit)</h4>
      <button id="q4-quant-refresh" class="btn-soft text-xs">Regenerate sample</button>
    </div>
    <p class="small-caption text-muted">See how weight distributions shift when you quantize the frozen base model. NF4 concentrates bins around zero so typical transformer weights stay close to their original values.</p>
    <div class="grid md:grid-cols-3 gap-4 items-start">
      <div class="md:col-span-2 space-y-3">
        <div class="grid grid-cols-2 gap-3">
          <div class="space-y-2">
            <div class="small-caption text-muted">Baseline: full precision</div>
            <canvas id="q4-quant-matrix-fp16" width="240" height="240" class="border border-subtle rounded bg-card w-full"></canvas>
          </div>
          <div class="space-y-2">
            <div id="q4-quant-label" class="small-caption text-muted">Quantized: 4-bit (NF4-like)</div>
            <canvas id="q4-quant-matrix-4bit" width="240" height="240" class="border border-subtle rounded bg-card w-full"></canvas>
          </div>
        </div>
        <p class="small-caption text-muted">They look similar because NF4 preserves small magnitudes. The histogram and error metrics reveal the aggregate impact across weights.</p>
        <div class="space-y-2">
          <div class="small-caption text-muted">Weight distribution and quantization levels</div>
          <canvas id="q4-quant-hist" width="520" height="160" class="border border-subtle rounded bg-card w-full"></canvas>
        </div>
        <div class="space-y-2">
          <label class="inline-flex items-center gap-2 text-xs text-secondary">
            <input id="q4-quant-show-diff" type="checkbox">
            <span class="text-muted">Show error heatmap (|full &minus; quant|)</span>
          </label>
          <div class="space-y-1 hidden" id="q4-quant-diff-wrap">
            <canvas id="q4-quant-diff" width="240" height="240" class="border border-subtle rounded bg-card w-full"></canvas>
            <p class="small-caption text-muted">Redder cells indicate larger per-weight error (exaggerated for visibility).</p>
          </div>
        </div>
      </div>
      <div class="space-y-2">
        <div class="panel panel-info p-3 text-xs space-y-1">
          <div class="font-medium text-heading">Bits per weight</div>
          <div id="q4-quant-bits" class="text-body">16 &rarr; 4 (4x reduction)</div>
        </div>
        <div class="panel panel-success p-3 text-xs space-y-1">
          <div class="font-medium text-heading">Approx. error</div>
          <div id="q4-quant-error" class="text-body">MSE: &mdash;, MAE: &mdash;</div>
        </div>
        <div class="panel panel-warning p-3 text-xs space-y-1">
          <div class="font-medium text-heading">Note</div>
          <div class="text-body">Uses an NF4-style non-uniform codebook that is denser near zero.</div>
        </div>
      </div>
    </div>
  </div>

  <!-- Technical Breakdown -->
  <div class="question-card space-y-3">
    <h4 class="font-medium text-heading">&#x1F4C8; Technical breakdown</h4>
    <div id="q4-breakdown" class="grid md:grid-cols-2 gap-4 text-sm"></div>
  </div>

  <!-- Practical Scenarios -->
  <div class="question-card space-y-3">
    <h4 class="font-medium text-heading">&#x1F3AE; Practical scenarios</h4>
    <div class="grid md:grid-cols-2 gap-3">
      <button id="q4-gpu-check" class="inline-flex flex-col items-start gap-1 px-3 py-2 text-sm font-medium border border-subtle rounded-md bg-card text-secondary hover:bg-subtle transition-colors">
        <span class="text-heading">&#x1F5A5;&#xFE0F; Check GPU compatibility</span>
        <span class="small-caption text-muted">Match methods to common single-GPU budgets.</span>
      </button>
      <button id="q4-cost-calc" class="inline-flex flex-col items-start gap-1 px-3 py-2 text-sm font-medium border border-subtle rounded-md bg-card text-secondary hover:bg-subtle transition-colors">
        <span class="text-heading">&#x1F4B0; Estimate training cost</span>
        <span class="small-caption text-muted">Approximate cloud runtime for each configuration.</span>
      </button>
    </div>
    <div id="q4-scenario-output" class="panel panel-neutral hidden">
      <div class="text-sm"></div>
    </div>
  </div>

  <!-- Educational Explanation -->
  <div id="q4-explanation" class="panel panel-warning p-4 space-y-2">
    <h4 class="font-medium">&#x1F4D2; How it works</h4>
    <div id="q4-explanation-content" class="text-sm">
      Select a fine-tuning method above to see how different approaches balance memory efficiency, training speed, and parameter reduction. Each method represents a different trade-off in the efficiency versus flexibility spectrum.
    </div>
  </div>
</div>