<div class="space-y-4">
  <div class="panel panel-info p-3">
    <h4 class="font-semibold mb-1">📚 Recommended reading (related)</h4>
    <ul class="list-disc ml-5 text-sm space-y-1">
      <li><a href="#question-01" class="underline">Question 1: What does tokenization entail?</a></li>
      <li><a href="#question-02" class="underline">Question 2: How does the attention mechanism function in transformer models?</a></li>
      <li><a href="#question-09" class="underline">Question 9: What is a transformer architecture?</a></li>
      <li><a href="#question-47" class="underline">Question 47: What is context and perplexity?</a></li>
    </ul>
  </div>

  <div class="panel panel-info panel-emphasis p-4 space-y-2">
    <h4 class="font-semibold">🧠 What are embeddings?</h4>
    <p>Embeddings map words, tokens, or concepts to dense high-dimensional vectors so that machines can operate on semantic meaning. They are the “coordinate system” that lets models compare ideas mathematically.</p>
  </div>

  <div class="grid md:grid-cols-3 gap-4">
    <div class="panel panel-success panel-emphasis p-3 space-y-2">
      <h5 class="font-medium">📍 Static embeddings</h5>
      <p class="text-sm">Fixed vector per word (Word2Vec, GloVe).</p>
      <div class="text-xs space-y-1">
        <div>✅ <strong>Simple:</strong> One vector per word.</div>
        <div>✅ <strong>Fast:</strong> Pre-computed lookups.</div>
        <div>❌ <strong>Context blind:</strong> "bank" never changes.</div>
        <div>❌ <strong>Limited:</strong> Cannot disambiguate meanings.</div>
      </div>
      <span class="chip chip-success text-xs">Examples: Word2Vec, GloVe</span>
    </div>

    <div class="panel panel-accent panel-emphasis p-3 space-y-2">
      <h5 class="font-medium">🎯 Contextual embeddings</h5>
      <p class="text-sm">Dynamic vectors conditioned on surrounding words (BERT, GPT).</p>
      <div class="text-xs space-y-1">
        <div>✅ <strong>Context aware:</strong> Captures polysemy.</div>
        <div>✅ <strong>Precise:</strong> Sensitive to sentence intent.</div>
        <div>✅ <strong>Rich:</strong> Encodes nuanced meaning.</div>
        <div>❌ <strong>Costly:</strong> Requires model inference.</div>
      </div>
      <span class="chip chip-accent text-xs">Examples: BERT, RoBERTa</span>
    </div>

    <div class="panel panel-warning panel-emphasis p-3 space-y-2">
      <h5 class="font-medium">🚀 Transformer embeddings</h5>
      <p class="text-sm">Stacked contextual layers used by modern LLMs.</p>
      <div class="text-xs space-y-1">
        <div>✅ <strong>Powerful:</strong> Deep, compositional signals.</div>
        <div>✅ <strong>Flexible:</strong> Task-specific heads.</div>
        <div>✅ <strong>Scalable:</strong> Works across long contexts.</div>
        <div>❌ <strong>Resource intensive:</strong> Needs compute + memory.</div>
      </div>
      <span class="chip chip-warning text-xs">Examples: GPT, T5, LLaMA</span>
    </div>
  </div>

  <div class="panel panel-warning p-4 space-y-2">
    <h4 class="font-semibold">🎯 Why embeddings matter</h4>
    <ul class="list-disc ml-5 text-sm space-y-1">
      <li><strong>Semantic understanding:</strong> Models compare meaning, not just tokens.</li>
      <li><strong>Vector arithmetic:</strong> Linear operations reveal relationships (e.g., king − man + woman ≈ queen).</li>
      <li><strong>Transfer learning:</strong> Pre-trained vectors bootstrap downstream tasks.</li>
      <li><strong>Product foundation:</strong> Underpins search, recommendation, retrieval-augmented generation, and more.</li>
    </ul>
  </div>

  <div class="panel panel-info p-4 space-y-3">
    <div class="space-y-1">
      <h4 class="font-semibold">🧭 Provider quick reference (2025)</h4>
      <ul class="list-disc ml-5 text-sm space-y-1">
        <li><strong>Similarity:</strong> Normalise vectors so cosine, dot, and Euclidean rank consistently.</li>
        <li><strong>Retrieval hints:</strong> Use provider flags (Cohere <code class="text-xs">input_type</code>, Voyage <code class="text-xs">input_type</code>, Google <code class="text-xs">task_type</code>) to optimise query/document encoders.</li>
        <li><strong>Dimensions:</strong> Cohere 256–1536, Google Gemini up to 3072 (<code class="text-xs">output_dimensionality</code>), Voyage 256–2048, Mistral fixed 1024.</li>
        <li><strong>Quantisation:</strong> Some APIs return <code class="text-xs">int8</code>/<code class="text-xs">binary</code>; bit-packed outputs may need unpacking before search.</li>
        <li><strong>Modalities:</strong> Cohere embed-v4.0 handles multilingual and text+image; Google exposes separate multimodal endpoints.</li>
        <li><strong>Batch limits (typical):</strong> Google ≈250 inputs/request, Cohere ≈96, Voyage up to 1000 (model dependent).</li>
      </ul>
    </div>
    <div class="space-y-1">
      <div class="text-xs font-semibold uppercase tracking-wide">Provider models</div>
      <ul class="list-disc ml-5 text-sm space-y-0.5">
        <li><strong>OpenAI:</strong> text-embedding-3 family</li>
        <li><strong>Google:</strong> gemini-embedding-001</li>
        <li><strong>Cohere:</strong> embed-v4.0</li>
        <li><strong>Mistral:</strong> mistral-embed</li>
        <li><strong>Voyage:</strong> voyage 3.x (large / 3.5 / lite)</li>
      </ul>
    </div>
    <p class="small-caption text-muted">Classic linear analogies are illustrative; modern sentence embeddings do not guarantee perfect vector arithmetic.</p>
  </div>
</div>
