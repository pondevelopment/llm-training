<div class="space-y-4">
  <div class="panel panel-info p-3">
    <h4 class="font-semibold mb-1">📚 Recommended reading (if these terms are new)</h4>
    <ul class="list-disc ml-5 text-sm space-y-1">
      <li><a href="#question-01" class="underline">Question 1: What is tokenization and why does it matter?</a></li>
      <li><a href="#question-12" class="underline">Question 12: Tokens vs. words — how are they different?</a></li>
    </ul>
  </div>

  <div class="panel panel-info p-4 space-y-2">
    <h4 class="font-semibold">🛠️ What are Out-of-Vocabulary (OOV) words?</h4>
    <p>Out-of-vocabulary words are the unfamiliar ingredients in a recipe. Older NLP systems replaced them with an “unknown” token, erasing nuance. Modern subword tokenizers split unfamiliar words into smaller, known pieces so models keep meaning even when they have never seen the exact term.</p>
  </div>

  <div class="grid md:grid-cols-3 gap-4">
    <div class="panel panel-success p-3">
      <div class="space-y-1">
        <h5 class="font-medium">🧩 Byte-Pair Encoding (BPE)</h5>
        <p class="text-sm text-body">Merges the most frequent character pairs to build a vocabulary of reusable subwords.</p>
      </div>
      <div class="panel panel-neutral-soft font-mono text-xs p-2">"cryptocurrency" → ["crypto", "currency"]</div>
    </div>

    <div class="panel panel-accent p-3">
      <div class="space-y-1">
        <h5 class="font-medium">🎯 SentencePiece</h5>
        <p class="text-sm text-body">Treats text as raw bytes so it can tokenise any language without a pre-tokeniser.</p>
      </div>
      <div class="panel panel-neutral-soft font-mono text-xs p-2">"▁crypto" + "currency"</div>
    </div>

    <div class="panel panel-warning p-3">
      <div class="space-y-1">
        <h5 class="font-medium">🔧 WordPiece</h5>
        <p class="text-sm text-body">Selects merges that maximise likelihood and leans on continuation markers.</p>
      </div>
      <div class="panel panel-neutral-soft font-mono text-xs p-2">"crypto" + "##currency"</div>
    </div>
  </div>

  <div class="panel panel-neutral p-4 space-y-3">
    <h4 class="font-semibold">⚙️ Subword tokenization workflow</h4>
    <div class="grid md:grid-cols-2 gap-4 text-sm">
      <div class="space-y-2">
        <h6 class="font-medium text-heading">Training phase</h6>
        <ul class="list-disc list-inside space-y-1 text-body">
          <li>Start with a character-level vocabulary.</li>
          <li>Count the frequency of character or byte pairs.</li>
          <li>Merge the most frequent pairs iteratively.</li>
          <li>Grow the subword inventory until the target size (for example, 50K tokens).</li>
          <li>Store merge rules and the final vocabulary.</li>
        </ul>
      </div>
      <div class="space-y-2">
        <h6 class="font-medium text-heading">Inference phase</h6>
        <ul class="list-disc list-inside space-y-1 text-body">
          <li>Apply the learned merge rules to new text.</li>
          <li>Break unfamiliar words into known subwords.</li>
          <li>Fall back to characters when no merges apply.</li>
          <li>Preserve semantic relationships via shared subpieces.</li>
          <li>Enable robust generation and understanding.</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="grid md:grid-cols-2 gap-4">
    <div class="panel panel-info p-3">
      <div class="space-y-1">
        <h5 class="font-medium">🌍 Multilingual handling</h5>
        <p class="text-sm text-body">Subword vocabularies naturally capture cross-lingual patterns when languages share roots or scripts.</p>
      </div>
      <div class="panel panel-neutral-soft font-mono text-xs p-2">"Tokyo" + "駅" → ["To", "ky", "o", "駅"]</div>
    </div>

    <div class="panel panel-success p-3">
      <div class="space-y-1">
        <h5 class="font-medium">🧪 Adaptive vocabularies</h5>
        <p class="text-sm text-body">Some models expand vocabularies during domain fine-tuning to catch specialised terms.</p>
      </div>
      <div class="panel panel-neutral-soft font-mono text-xs p-2">Medical example: "cardio" + "vascular" + "itis"</div>
    </div>
  </div>

  <div class="panel panel-warning p-4 space-y-3">
    <h4 class="font-semibold">🎯 Key benefits of subword tokenization</h4>
    <div class="grid md:grid-cols-2 gap-4 text-sm">
      <div class="space-y-2">
        <h6 class="font-medium text-heading">Robustness</h6>
        <ul class="list-disc list-inside space-y-1">
          <li><strong>No “UNK” tokens:</strong> Every word receives a representation.</li>
          <li><strong>Morphological awareness:</strong> Captures prefixes, stems, and suffixes.</li>
          <li><strong>Cross-lingual transfer:</strong> Shares subwords across related languages.</li>
          <li><strong>Domain adaptation:</strong> Handles fast-changing terminology.</li>
        </ul>
      </div>
      <div class="space-y-2">
        <h6 class="font-medium text-heading">Efficiency</h6>
        <ul class="list-disc list-inside space-y-1">
          <li><strong>Vocabulary control:</strong> Keeps lookup tables bounded.</li>
          <li><strong>Better compression:</strong> Balances sequence length with coverage.</li>
          <li><strong>Semantic preservation:</strong> Reuses meaningful building blocks.</li>
          <li><strong>Training stability:</strong> Produces consistent token distributions.</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="panel panel-success p-4 space-y-3 text-sm">
    <h4 class="font-semibold">🌟 Real-world OOV handling examples</h4>
    <div class="grid md:grid-cols-2 gap-4">
      <div class="space-y-2">
        <h6 class="font-medium text-heading">Technical terms</h6>
        <ul class="list-disc list-inside space-y-1">
          <li>"blockchain" → ["block", "chain"]</li>
          <li>"cryptocurrency" → ["crypto", "currency"]</li>
          <li>"biodegradable" → ["bio", "de", "grad", "able"]</li>
          <li>"neuroscientist" → ["neuro", "scientist"]</li>
        </ul>
      </div>
      <div class="space-y-2">
        <h6 class="font-medium text-heading">Proper nouns &amp; neologisms</h6>
        <ul class="list-disc list-inside space-y-1">
          <li>"COVID-19" → ["COVID", "-", "19"]</li>
          <li>"Pokémon" → ["Po", "ké", "mon"]</li>
          <li>"unfriend" → ["un", "friend"]</li>
          <li>"livestream" → ["live", "stream"]</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="panel panel-warning p-4 space-y-2 text-sm">
    <h4 class="font-semibold">⚠️ Challenges and considerations</h4>
    <p><strong>Semantic boundaries:</strong> Subword splits may ignore morphology, muddying meaning.</p>
    <p><strong>Sequence length:</strong> More tokens per word mean higher compute costs.</p>
    <p><strong>Training data bias:</strong> Vocabularies mirror the corpora they were trained on, underrepresenting niche languages or domains.</p>
    <p><strong>Consistency across tokenizers:</strong> Different merge rules can represent the same concept differently.</p>
  </div>
</div>