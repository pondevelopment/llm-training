<div class="space-y-4">
    <!-- Recommended Reading (Cross-links) -->
    <div class="bg-indigo-50 p-3 rounded-lg border border-indigo-200">
      <h4 class="font-semibold text-indigo-900 mb-1">ðŸ“š Recommended reading</h4>
      <ul class="list-disc ml-5 text-sm text-indigo-800 space-y-1">
        <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-2">Question 2: How do attention mechanisms work?</a></li>
        <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-16">Question 16: What is transfer learning in LLMs?</a></li>
        <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-22">Question 22: What is multiâ€‘head attention?</a></li>
        <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-32">Question 32: How are attention scores calculated?</a></li>
        <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-33">Question 33: How do multimodal training strategies differ?</a></li>
      </ul>
  <p class="text-xs text-indigo-700 mt-2">These provide prerequisites on attention, transfer, and multimodal integration that inform foundation model taxonomy.</p>
    </div>
    <!-- Definition / Overview -->
  <div class="bg-blue-50 p-4 rounded-lg border-l-4 border-blue-400">
      <h4 class="font-semibold text-blue-900 mb-2">ðŸ§± What is a Foundation Model?</h4>
    <p class="text-sm text-blue-800 leading-relaxed">A <strong>foundation model</strong> is a very large, broadly trained model (usually self-supervised) that learns general representations and can be <em>adapted</em> to many downstream tasks via prompting, fineâ€‘tuning, retrieval, tools, or lightweight parameter updates (e.g., LoRA). They span multiple <strong>modalities</strong> (text, images, audio, video, 3D, code, bio, robotics) and often unify them inside Transformer or hybrid attention architectures.</p>
      <div class="mt-3 grid md:grid-cols-4 gap-3 text-xs">
        <div class="bg-white rounded p-3 border border-blue-100"><span class="font-semibold">Training</span><br>Massive unlabeled corpora + self / weak supervision</div>
        <div class="bg-white rounded p-3 border border-blue-100"><span class="font-semibold">Adaptation</span><br>Prompting Â· RAG Â· Fineâ€‘tune Â· LoRA Â· Distillation</div>
        <div class="bg-white rounded p-3 border border-blue-100"><span class="font-semibold">Economics</span><br>High pretrain cost â†’ Low marginal task cost</div>
        <div class="bg-white rounded p-3 border border-blue-100"><span class="font-semibold">Scaling Law</span><br>Perplexity â†“ â‰ˆ powerâ€‘law in (Parameters, Data, Compute)</div>
      </div>
    </div>

    <!-- Taxonomy Summary Grid -->
  <div class="bg-white p-4 rounded-lg border border-gray-200 shadow-sm">
      <h4 class="font-semibold text-gray-900 mb-4 flex items-center">ðŸ“š Major Foundation Model Categories</h4>
      <div class="grid lg:grid-cols-3 md:grid-cols-2 gap-5 text-sm">
        <div class="bg-gradient-to-br from-indigo-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-indigo-800 mb-1">1. Language / Multilingual</h5>
          <p class="text-indigo-700 text-xs mb-1">Autoregressive or masked Transformers over tokenized text.</p>
          <ul class="list-disc ml-4 text-xs space-y-0.5 text-indigo-700">
            <li>GPTâ€‘5, GPTâ€‘4o / 4.1 / 4.5 family</li>
            <li>Claude 3 / 3.5 (Opus, Sonnet, Haiku)</li>
            <li>Gemini 2.5 (Pro / Flash / Flashâ€‘Lite)</li>
            <li>Llama 3 (8B / 70B), Mistral Large</li>
            <li>Mixtral 8x7B, Qwen2, DeepSeekâ€‘V2</li>
            <li>Yi, Phiâ€‘3, Command R+</li>
          </ul>
        </div>
        <div class="bg-gradient-to-br from-purple-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-purple-800 mb-1">2. Vision & Vision-Language</h5>
          <p class="text-purple-700 text-xs mb-1">Image / video encoders & joint visual-text reasoning.</p>
          <ul class="list-disc ml-4 text-xs space-y-0.5 text-purple-700">
            <li>ViT, ConvNeXt, EVA (encoders)</li>
            <li>CLIP / SigLIP (align textâ€“image)</li>
            <li>SAM, Florenceâ€‘2, Grounding DINO</li>
            <li>Kosmos, LLaVA, InstructBLIP</li>
          </ul>
        </div>
        <div class="bg-gradient-to-br from-rose-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-rose-800 mb-1">3. Image Generation</h5>
            <p class="text-rose-700 text-xs mb-1">Diffusion, rectified flow & transformer decoders.</p>
            <ul class="list-disc ml-4 text-xs space-y-0.5 text-rose-700">
              <li>SDXL 1.0, Flux.1, Stable Cascade</li>
              <li>Midjourney v6, DALLÂ·E 3</li>
              <li>Ideogram 2, Firefly 3</li>
              <li>Imagen 3, Kandinsky 3</li>
            </ul>
        </div>
        <div class="bg-gradient-to-br from-emerald-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-emerald-800 mb-1">4. Audio / Speech / Music</h5>
          <p class="text-emerald-700 text-xs mb-1">Waveform, spectrogram & token based generative models.</p>
          <ul class="list-disc ml-4 text-xs space-y-0.5 text-emerald-700">
            <li>Whisper, MMS, NeMo ASR</li>
            <li>Bark, WaveNet, XTTS</li>
            <li>Suno v3, Udio, MusicGen, Lyria</li>
            <li>AudioLM, LMâ€‘based TTS (Voicebox)</li>
          </ul>
        </div>
        <div class="bg-gradient-to-br from-amber-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-amber-800 mb-1">5. Video & World Models</h5>
          <p class="text-amber-700 text-xs mb-1">Temporal latent dynamics & 3D world simulation.</p>
          <ul class="list-disc ml-4 text-xs space-y-0.5 text-amber-700">
            <li>Sora (textâ†’video), Veo</li>
            <li>Runway Genâ€‘3 / Genâ€‘3 Alpha</li>
            <li>Kling, Pika Labs, Dream Machine</li>
            <li>Genie, World Model (Runway), GAIAâ€‘1</li>
          </ul>
        </div>
        <div class="bg-gradient-to-br from-fuchsia-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-fuchsia-800 mb-1">6. Code & Tool Models</h5>
          <p class="text-fuchsia-700 text-xs mb-1">Enhanced reasoning over structured syntax & repos.</p>
          <ul class="list-disc ml-4 text-xs space-y-0.5 text-fuchsia-700">
            <li>Code Llama, StarCoder2</li>
            <li>DeepSeekâ€‘Coder V2, GPTâ€‘4.1</li>
            <li>Claude Code, Gemini Code Assist</li>
            <li>Phind, WizardCoder, Granite</li>
          </ul>
        </div>
        <div class="bg-gradient-to-br from-lime-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-lime-800 mb-1">7. Scientific / Domain</h5>
          <p class="text-lime-700 text-xs mb-1">Specialized biological, medical & chemical modeling.</p>
          <ul class="list-disc ml-4 text-xs space-y-0.5 text-lime-700">
            <li>AlphaFold2 / AF-Multimer, ESMâ€‘2</li>
            <li>GNoME (materials), Fractal</li>
            <li>Med-PaLM 2, BioGPT, PubMedBERT</li>
            <li>GenSLM, TimeGPT (forecast)</li>
          </ul>
        </div>
        <div class="bg-gradient-to-br from-slate-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-slate-800 mb-1">8. Multimodal Unified</h5>
          <p class="text-slate-700 text-xs mb-1">Single model with shared token space across modalities.</p>
          <ul class="list-disc ml-4 text-xs space-y-0.5 text-slate-700">
            <li>Gemini 2.5 (native multi), GPTâ€‘5, GPTâ€‘4o</li>
            <li>Claude 3.5 Sonnet, Qwen2-VL</li>
            <li>InternVL 2, LLaVA 1.6</li>
            <li>Fuyu, InstructBLIP, MiniCPMâ€‘V</li>
          </ul>
        </div>
        <div class="bg-gradient-to-br from-teal-50 to-white border rounded-lg p-4">
          <h5 class="font-semibold text-teal-800 mb-1">9. Robotics / VLA</h5>
          <p class="text-teal-700 text-xs mb-1">Visionâ€‘Languageâ€‘Action grounding & policy generation.</p>
          <ul class="list-disc ml-4 text-xs space-y-0.5 text-teal-700">
            <li>RTâ€‘2 / RTâ€‘X, OpenVLA</li>
            <li>RoboCat, PaLMâ€‘E, Octo</li>
            <li>GR00T, ALOHA, Mobile ALOHA</li>
            <li>MimicGen, Generalist VLA stacks</li>
          </ul>
        </div>
      </div>
  <p class="text-xs text-gray-500 mt-2">Model lists are illustrative (mixed open / closed, 2023â€“2025). Presence â‰  endorsement; update periodically as families evolve.</p>
  </div>

    <!-- Adaptation Patterns -->
  <div class="bg-yellow-50 p-4 rounded-lg">
      <h4 class="font-semibold text-yellow-900 mb-2">ðŸ”§ Common Adaptation & Extension Patterns</h4>
      <div class="grid md:grid-cols-3 gap-4 text-xs">
        <div class="bg-white rounded p-3 border border-yellow-100">
          <h6 class="font-semibold mb-1">Prompt & Inâ€‘Context</h6>
          <ul class="list-disc ml-4 space-y-0.5 text-yellow-800">
            <li>Task encoding via instructions / exemplars</li>
            <li>Augment context length (RAG, memory)</li>
            <li>No weight updates â†’ instant iteration</li>
          </ul>
        </div>
        <div class="bg-white rounded p-3 border border-yellow-100">
          <h6 class="font-semibold mb-1">Parameter Efficient</h6>
          <ul class="list-disc ml-4 space-y-0.5 text-yellow-800">
            <li>LoRA / IAÂ³ / QLoRA adapters</li>
            <li>Prefix / Pâ€‘tuning v2 / Side modules</li>
            <li>Low compute fineâ€‘tunes</li>
          </ul>
        </div>
        <div class="bg-white rounded p-3 border border-yellow-100">
          <h6 class="font-semibold mb-1">Retrieval & Tool Use</h6>
          <ul class="list-disc ml-4 space-y-0.5 text-yellow-800">
            <li>Structured indexes (vector / graph)</li>
            <li>Grounding via APIs, databases, search</li>
            <li>External execution (code / agents)</li>
          </ul>
        </div>
      </div>
  <p class="text-xs text-yellow-700 mt-3">Other extensions: Distillation â†’ smaller student models; Mixtureâ€‘ofâ€‘Experts for routing; Guardrails & safety filters for alignment.</p>
    </div>

    <!-- Why It Matters -->
  <div class="bg-green-50 p-4 rounded-lg">
      <h4 class="font-semibold text-green-900 mb-2">ðŸŽ¯ Why This Taxonomy Matters</h4>
      <ul class="text-sm text-green-800 space-y-1">
        <li>â€¢ <strong>Strategic Alignment:</strong> Helps decide whether to prompt, retrieve, or fineâ€‘tune for a given task.</li>
        <li>â€¢ <strong>Cost Optimization:</strong> High pretrain cost justifies reuseâ€”adapters & RAG reduce duplication.</li>
        <li>â€¢ <strong>Capability Planning:</strong> Understanding modality coverage guides product roadmaps.</li>
        <li>â€¢ <strong>Risk & Governance:</strong> Different categories pose distinct safety / bias / IP profiles.</li>
      </ul>
    </div>
  </div>
