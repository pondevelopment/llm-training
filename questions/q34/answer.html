<div class="space-y-6 q34-answer">
  <style>
    .q34-answer .q34-support {
      font-size: 0.75rem;
      color: var(--color-muted);
    }

    .q34-answer .q34-mini-card {
      display: flex;
      flex-direction: column;
      gap: 0.35rem;
      font-size: 0.75rem;
      padding: 0.75rem;
      --panel-bg: color-mix(in srgb, var(--color-card) 70%, transparent 30%);
      --panel-border: color-mix(in srgb, var(--color-border-subtle) 80%, transparent 20%);
    }

    .q34-answer .q34-mini-card strong {
      font-size: 0.85rem;
      color: var(--color-heading);
    }

    .q34-answer .q34-mini-card span {
      display: block;
    }

    .q34-answer .q34-mini-card ul {
      margin: 0;
      padding-left: 1rem;
      line-height: 1.45;
    }

    .q34-answer .q34-card {
      display: flex;
      flex-direction: column;
      gap: 0.6rem;
      font-size: 0.85rem;
      padding: 1rem;
    }

    .q34-answer .q34-card p {
      margin: 0;
      font-size: 0.8rem;
      line-height: 1.4;
    }

    .q34-answer .q34-card ul {
      margin: 0;
      padding-left: 1.1rem;
      font-size: 0.75rem;
      line-height: 1.45;
    }

    .q34-answer .q34-card[data-accent] {
      --panel-bg: color-mix(in srgb, var(--accent-soft) 70%, var(--color-card) 30%);
      --panel-border: color-mix(in srgb, var(--accent-border) 70%, transparent 30%);
      --panel-heading: var(--accent-text);
      --panel-text: color-mix(in srgb, var(--accent-text) 40%, var(--color-body) 60%);
    }

    html.dark .q34-answer .q34-card[data-accent] {
      --panel-bg: color-mix(in srgb, var(--accent-soft) 55%, var(--color-card) 45%);
      --panel-text: color-mix(in srgb, var(--accent-text) 55%, var(--color-body) 45%);
    }

    .q34-answer .q34-footnote {
      font-size: 0.7rem;
      color: var(--color-muted);
    }
  </style>

  <div class="panel panel-info panel-emphasis p-4 space-y-2">
    <h4 class="text-heading font-semibold">ðŸ“š Recommended reading</h4>
    <ul class="list-disc ml-5 text-sm space-y-1">
      <li><a class="text-link" href="#question-2">Question 2: How do attention mechanisms work?</a></li>
      <li><a class="text-link" href="#question-16">Question 16: What is transfer learning in LLMs?</a></li>
      <li><a class="text-link" href="#question-22">Question 22: What is multiâ€‘head attention?</a></li>
      <li><a class="text-link" href="#question-32">Question 32: How are attention scores calculated?</a></li>
      <li><a class="text-link" href="#question-33">Question 33: How do multimodal training strategies differ?</a></li>
    </ul>
    <p class="q34-support">These provide prerequisites on attention, transfer, and multimodal integration that inform foundation model taxonomy.</p>
  </div>

  <div class="panel panel-info panel-emphasis p-4 space-y-3">
    <h4 class="text-heading font-semibold">ðŸ§± What is a Foundation Model?</h4>
    <p class="text-sm text-body leading-relaxed">A <strong>foundation model</strong> is a very large, broadly trained model (usually self-supervised) that learns general representations and can be <em>adapted</em> to many downstream tasks via prompting, fineâ€‘tuning, retrieval, tools, or lightweight parameter updates (e.g., LoRA). They span multiple <strong>modalities</strong> (text, images, audio, video, 3D, code, bio, robotics) and often unify them inside Transformer or hybrid attention architectures.</p>
    <div class="grid gap-3 md:grid-cols-4">
      <div class="panel panel-neutral-soft q34-mini-card"><strong>Training</strong><span>Massive unlabeled corpora + self / weak supervision</span></div>
      <div class="panel panel-neutral-soft q34-mini-card"><strong>Adaptation</strong><span>Prompting Â· RAG Â· Fineâ€‘tune Â· LoRA Â· Distillation</span></div>
      <div class="panel panel-neutral-soft q34-mini-card"><strong>Economics</strong><span>High pretrain cost â†’ low marginal task cost</span></div>
      <div class="panel panel-neutral-soft q34-mini-card"><strong>Scaling Law</strong><span>Perplexity â†“ â‰ˆ powerâ€‘law in (parameters, data, compute)</span></div>
    </div>
  </div>

  <div class="panel panel-neutral p-4 space-y-4">
    <h4 class="text-heading font-semibold">ðŸ“š Major Foundation Model Categories</h4>
    <div class="grid gap-4 md:grid-cols-2 lg:grid-cols-3">
      <div class="panel q34-card" data-accent="foundations">
        <h5 class="text-heading font-semibold text-sm">1. Language / Multilingual</h5>
        <p>Autoregressive or masked Transformers over tokenized text.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>GPTâ€‘5, GPTâ€‘4o / 4.1 / 4.5 family</li>
          <li>Claude 3 / 3.5 (Opus, Sonnet, Haiku)</li>
          <li>Gemini 2.5 (Pro / Flash / Flashâ€‘Lite)</li>
          <li>Llama 3 (8B / 70B), Mistral Large</li>
          <li>Mixtral 8x7B, Qwen2, DeepSeekâ€‘V2</li>
          <li>Yi, Phiâ€‘3, Command R+</li>
        </ul>
      </div>

      <div class="panel q34-card" data-accent="training">
        <h5 class="text-heading font-semibold text-sm">2. Vision &amp; Vision-Language</h5>
        <p>Image / video encoders &amp; joint visual-text reasoning.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>ViT, ConvNeXt, EVA (encoders)</li>
          <li>CLIP / SigLIP (align textâ€“image)</li>
          <li>SAM, Florenceâ€‘2, Grounding DINO</li>
          <li>Kosmos, LLaVA, InstructBLIP</li>
        </ul>
      </div>

      <div class="panel q34-card" data-accent="generation">
        <h5 class="text-heading font-semibold text-sm">3. Image Generation</h5>
        <p>Diffusion, rectified flow &amp; transformer decoders.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>SDXL 1.0, Flux.1, Stable Cascade</li>
          <li>Midjourney v6, DALLÂ·E 3</li>
          <li>Ideogram 2, Firefly 3</li>
          <li>Imagen 3, Kandinsky 3</li>
        </ul>
      </div>

      <div class="panel q34-card" data-accent="alignment">
        <h5 class="text-heading font-semibold text-sm">4. Audio / Speech / Music</h5>
        <p>Waveform, spectrogram &amp; token based generative models.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>Whisper, MMS, NeMo ASR</li>
          <li>Bark, WaveNet, XTTS</li>
          <li>Suno v3, Udio, MusicGen, Lyria</li>
          <li>AudioLM, LMâ€‘based TTS (Voicebox)</li>
        </ul>
      </div>

      <div class="panel q34-card" data-accent="scaling">
        <h5 class="text-heading font-semibold text-sm">5. Video &amp; World Models</h5>
        <p>Temporal latent dynamics &amp; 3D world simulation.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>Sora (textâ†’video), Veo</li>
          <li>Runway Genâ€‘3 / Genâ€‘3 Alpha</li>
          <li>Kling, Pika Labs, Dream Machine</li>
          <li>Genie, World Model (Runway), GAIAâ€‘1</li>
        </ul>
      </div>

      <div class="panel q34-card" data-accent="training">
        <h5 class="text-heading font-semibold text-sm">6. Code &amp; Tool Models</h5>
        <p>Enhanced reasoning over structured syntax &amp; repos.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>Code Llama, StarCoder2</li>
          <li>DeepSeekâ€‘Coder V2, GPTâ€‘4.1</li>
          <li>Claude Code, Gemini Code Assist</li>
          <li>Phind, WizardCoder, Granite</li>
        </ul>
      </div>

      <div class="panel q34-card" data-accent="alignment">
        <h5 class="text-heading font-semibold text-sm">7. Scientific / Domain</h5>
        <p>Specialized biological, medical &amp; chemical modeling.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>AlphaFold2 / AF-Multimer, ESMâ€‘2</li>
          <li>GNoME (materials), Fractal</li>
          <li>Med-PaLM 2, BioGPT, PubMedBERT</li>
          <li>GenSLM, TimeGPT (forecast)</li>
        </ul>
      </div>

      <div class="panel q34-card" data-accent="foundations">
        <h5 class="text-heading font-semibold text-sm">8. Multimodal Unified</h5>
        <p>Single model with shared token space across modalities.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>Gemini 2.5 (native multi), GPTâ€‘5, GPTâ€‘4o</li>
          <li>Claude 3.5 Sonnet, Qwen2-VL</li>
          <li>InternVL 2, LLaVA 1.6</li>
          <li>Fuyu, InstructBLIP, MiniCPMâ€‘V</li>
        </ul>
      </div>

      <div class="panel q34-card" data-accent="scaling">
        <h5 class="text-heading font-semibold text-sm">9. Robotics / VLA</h5>
        <p>Vision-Language-Action grounding &amp; policy generation.</p>
        <ul class="list-disc ml-4 space-y-1">
          <li>RTâ€‘2 / RTâ€‘X, OpenVLA</li>
          <li>RoboCat, PaLMâ€‘E, Octo</li>
          <li>GR00T, ALOHA, Mobile ALOHA</li>
          <li>MimicGen, Generalist VLA stacks</li>
        </ul>
      </div>
    </div>
    <p class="q34-footnote">Model lists are illustrative (mixed open / closed, 2023â€“2025). Presence â‰  endorsement; update periodically as families evolve.</p>
  </div>

  <div class="panel panel-warning p-4 space-y-3">
    <h4 class="text-heading font-semibold">ðŸ”§ Common Adaptation &amp; Extension Patterns</h4>
    <div class="grid gap-4 md:grid-cols-3 text-sm">
      <div class="panel panel-neutral-soft q34-mini-card">
        <strong>Prompt &amp; In-Context</strong>
        <ul class="list-disc ml-4 space-y-1">
          <li>Task encoding via instructions / exemplars</li>
          <li>Augment context length (RAG, memory)</li>
          <li>No weight updates â†’ instant iteration</li>
        </ul>
      </div>
      <div class="panel panel-neutral-soft q34-mini-card">
        <strong>Parameter Efficient</strong>
        <ul class="list-disc ml-4 space-y-1">
          <li>LoRA / IAÂ³ / QLoRA adapters</li>
          <li>Prefix / P-tuning v2 / side modules</li>
          <li>Low compute fine-tunes</li>
        </ul>
      </div>
      <div class="panel panel-neutral-soft q34-mini-card">
        <strong>Retrieval &amp; Tool Use</strong>
        <ul class="list-disc space-y-1">
          <li>Structured indexes (vector / graph)</li>
          <li>Grounding via APIs, databases, search</li>
          <li>External execution (code / agents)</li>
        </ul>
      </div>
    </div>
    <p class="q34-support">Other extensions: distillation â†’ smaller student models; mixture-of-experts for routing; guardrails &amp; safety filters for alignment.</p>
  </div>

  <div class="panel panel-success p-4 space-y-2">
    <h4 class="text-heading font-semibold">ðŸŽ¯ Why This Taxonomy Matters</h4>
    <ul class="text-sm space-y-1">
      <li><strong>Strategic alignment:</strong> Helps decide whether to prompt, retrieve, or fineâ€‘tune for a given task.</li>
      <li><strong>Cost optimization:</strong> High pretrain cost justifies reuseâ€”adapters &amp; RAG reduce duplication.</li>
      <li><strong>Capability planning:</strong> Understanding modality coverage guides product roadmaps.</li>
      <li><strong>Risk &amp; governance:</strong> Different categories pose distinct safety, bias, and IP profiles.</li>
    </ul>
  </div>
</div>
