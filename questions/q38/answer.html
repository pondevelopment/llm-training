<div class="space-y-4">
  <div class="panel panel-info p-3">
    <h4 class="font-semibold mb-1">üìö Recommended reading</h4>
    <ul class="list-disc ml-5 text-sm space-y-1 panel-muted">
      <li><a class="underline" href="#question-12">Question 12: Prompt engineering basics</a></li>
      <li><a class="underline" href="#question-31">Question 31: Temperature & sampling</a></li>
      <li><a class="underline" href="#question-36">Question 36: Retrieval-Augmented Generation</a></li>
      <li><a class="underline" href="#question-37">Question 37: Mixture of Experts</a></li>
    </ul>
  </div>

  <div class="panel panel-info panel-emphasis p-4 space-y-3">
    <h4 class="font-semibold">üß† Key idea</h4>
    <p class="text-sm leading-relaxed"><strong>Chain-of-Thought (CoT)</strong> prompting asks the model to <strong>show intermediate steps</strong> rather than jumping straight to the final answer. This structured reasoning improves results on multi-step tasks (math word problems, logic, program synthesis).</p>
    <div id="q38-key-math" class="math-display text-xs font-mono"></div>
    <p class="text-xs panel-muted">Here <span class="font-mono">p</span> is the probability a single CoT sample is correct. Sampling multiple CoT chains at higher temperature and <em>voting</em> often boosts accuracy.</p>
  </div>

  <div class="grid md:grid-cols-3 gap-4">
    <div class="panel panel-success panel-emphasis p-3 space-y-2">
      <h5 class="font-semibold text-sm">Direct answer</h5>
      <p class="text-sm">Model outputs an answer immediately. <strong>Lowest cost</strong>, but can fail on multi-step logic.</p>
      <div class="math-display text-xs font-mono">$$ y = f(\text{prompt}) $$</div>
      <ul class="list-disc ml-4 text-xs panel-muted space-y-1">
        <li>Fast, cheap</li>
        <li>No transparency</li>
      </ul>
    </div>

    <div class="panel panel-accent panel-emphasis p-3 space-y-2">
      <h5 class="font-semibold text-sm">Single CoT</h5>
      <p class="text-sm">Ask the model to ‚Äúthink step by step.‚Äù Decomposes reasoning and surfaces intermediate checks.</p>
      <div class="math-display text-xs font-mono">$$ y = g(s_1, s_2, \dots, s_T) $$</div>
      <ul class="list-disc ml-4 text-xs panel-muted space-y-1">
        <li>Better reasoning</li>
      </ul>
      <p class="text-xs panel-muted">For self-consistency, sample <span class="font-mono">m</span> CoT chains at moderate temperature and vote on the final answer.</p>
    </div>

    <div class="panel panel-warning panel-emphasis p-3 space-y-2">
      <h5 class="font-semibold text-sm">Self-consistency</h5>
      <p class="text-sm">Sample multiple diverse CoT chains and <strong>vote</strong> on the final answer. Robust to a bad chain.</p>
      <div class="math-display text-xs font-mono">$$ P_{\mathrm{SC}} = \sum_{k=t}^{m} \binom{m}{k} p^{k} (1-p)^{m-k} $$</div>
      <ul class="list-disc ml-4 text-xs panel-muted space-y-1">
        <li>Higher accuracy</li>
        <li>Higher cost</li>
      </ul>
    </div>
  </div>

  <div class="panel panel-warning p-4 space-y-2">
    <h4 class="font-semibold mb-1">üéØ Why this matters</h4>
    <ul class="list-disc ml-5 text-sm space-y-1 panel-muted">
      <li><strong>Decomposes</strong> complex problems into smaller steps.</li>
      <li><strong>Improves reliability</strong> on math and logic tasks vs. direct answers.</li>
      <li><strong>Self-consistency</strong> boosts accuracy by sampling diverse chains and voting.</li>
      <li><strong>Trade-off:</strong> CoT uses more tokens (cost/latency) for better accuracy.</li>
    </ul>
  </div>
</div>
