<div class="space-y-4">
    <div class="bg-indigo-50 p-3 rounded-lg border border-indigo-200">
      <h4 class="font-semibold text-indigo-900 mb-1">üìö Recommended reading (related)</h4>
      <ul class="list-disc ml-5 text-sm text-indigo-800 space-y-1">
  <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-04">Question 4: LoRA vs QLoRA</a></li>
  <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-13">Question 13: Prompt engineering</a></li>
  <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-14">Question 14: Catastrophic forgetting</a></li>
  <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-34">Question 34: Foundation model adaptation modes</a></li>
  <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-36">Question 36: Retrieval-Augmented Generation (RAG)</a></li>
  <li><a class="text-indigo-700 underline hover:text-indigo-900" href="#question-49">Question 49: What defines an LLM?</a></li>
      </ul>
    </div>
    <div class="bg-blue-50 p-4 rounded-lg border-l-4 border-blue-400 space-y-2">
      <h4 class="font-semibold text-blue-900">üîç Core Question</h4>
      <p class="text-sm text-blue-800 leading-relaxed"><strong>You should NOT fine-tune by default.</strong> Move upward through adaptation steps: better prompting ‚Üí retrieval (RAG) ‚Üí lightweight parameter adaptation (adapters / LoRA) ‚Üí **full or targeted fine-tuning** only if persistent, structural, or distributional gaps remain and retrieval cannot bridge them efficiently.</p>
    </div>
    <div class="grid md:grid-cols-4 gap-4 text-sm">
      <div class="bg-white p-3 rounded border-l-4 border-emerald-400">
        <h5 class="font-medium text-emerald-800 mb-1">Prompting</h5>
        <p class="text-xs text-emerald-700 leading-snug">Fast iteration. Great for style & task framing. Weak on private / large corpora.</p>
      </div>
      <div class="bg-white p-3 rounded border-l-4 border-indigo-400">
        <h5 class="font-medium text-indigo-800 mb-1">RAG</h5>
        <p class="text-xs text-indigo-700 leading-snug">Fresh facts & proprietary knowledge via retrieval. Needs high hit rate + grounding.</p>
      </div>
      <div class="bg-white p-3 rounded border-l-4 border-purple-400">
        <h5 class="font-medium text-purple-800 mb-1">Adapters</h5>
        <p class="text-xs text-purple-700 leading-snug">Parameter‚Äëefficient shaping: style, format, compliance layers.</p>
      </div>
      <div class="bg-white p-3 rounded border-l-4 border-rose-400">
        <h5 class="font-medium text-rose-800 mb-1">Full Fine-tune</h5>
        <p class="text-xs text-rose-700 leading-snug">Expensive & sticky. Use when distribution shift + stable domain + scale justify.</p>
      </div>
    </div>
    <div class="bg-yellow-50 p-4 rounded-lg border border-yellow-200">
      <h4 class="font-semibold text-yellow-900 mb-2">üß≠ Escalation Ladder</h4>
      <ol class="list-decimal ml-5 space-y-1 text-yellow-800 text-sm">
        <li>Prompt engineering + response format exemplars</li>
        <li>Introduce retrieval (chunking, rerank, grounding)</li>
        <li>Add adapters (LoRA) for consistent style / schema</li>
        <li>Targeted fine-tune (narrow layers or SFT set)</li>
        <li>Hybrid: RAG + adapters + selective fine-tune</li>
      </ol>
    </div>
    <div class="bg-white border rounded-lg p-4">
      <h4 class="font-semibold text-gray-800 mb-3">üìä Decision Signals (quick scan)</h4>
      <div class="grid md:grid-cols-2 gap-3 text-[12px]">
        <div class="p-3 rounded border bg-gray-50">
          <div class="flex items-center justify-between mb-1"><span class="font-medium text-gray-800">Fresh / rapidly changing facts</span><span class="text-[10px] px-2 py-0.5 rounded bg-indigo-100 text-indigo-700">RAG</span></div>
          <p class="text-gray-600 leading-snug">Prefer <strong>RAG</strong>. Fine-tuning lags updates; hybrid only if formatting/style also critical.</p>
        </div>
        <div class="p-3 rounded border bg-gray-50">
          <div class="flex items-center justify-between mb-1"><span class="font-medium text-gray-800">Stable proprietary corpus</span><span class="text-[10px] px-2 py-0.5 rounded bg-rose-100 text-rose-700">Fine-tune</span></div>
          <p class="text-gray-600 leading-snug">If updates are infrequent & scale high, a targeted fine-tune (or hybrid) amortizes lookup cost.</p>
        </div>
        <div class="p-3 rounded border bg-gray-50">
          <div class="flex items-center justify-between mb-1"><span class="font-medium text-gray-800">Strict output schema / JSON</span><span class="text-[10px] px-2 py-0.5 rounded bg-purple-100 text-purple-700">Adapter</span></div>
          <p class="text-gray-600 leading-snug">Start with <strong>adapter / constrained decoding</strong>; full fine-tune only if persistent structural errors remain.</p>
        </div>
        <div class="p-3 rounded border bg-gray-50">
          <div class="flex items-center justify-between mb-1"><span class="font-medium text-gray-800">Ultra low latency (&lt;300ms)</span><span class="text-[10px] px-2 py-0.5 rounded bg-emerald-100 text-emerald-700">Prompt</span></div>
          <p class="text-gray-600 leading-snug">Avoid extra retrieval hops. Cache + distilled / adapter variants; hybrid only if facts must stay fresh.</p>
        </div>
        <div class="p-3 rounded border bg-gray-50">
          <div class="flex items-center justify-between mb-1"><span class="font-medium text-gray-800">Per‚Äëuser personalization</span><span class="text-[10px] px-2 py-0.5 rounded bg-rose-100 text-rose-700">Fine-tune / Hybrid</span></div>
          <p class="text-gray-600 leading-snug">High granularity personalization often needs <strong>adapter stacks or selective fine-tune</strong>.</p>
        </div>
        <div class="p-3 rounded border bg-gray-50">
          <div class="flex items-center justify-between mb-1"><span class="font-medium text-gray-800">Massive query volume</span><span class="text-[10px] px-2 py-0.5 rounded bg-rose-100 text-rose-700">Fine-tune</span></div>
          <p class="text-gray-600 leading-snug">Per‚Äëquery retrieval cost dominates at scale; <strong>model-internalization</strong> can lower marginal latency.</p>
        </div>
        <div class="p-3 rounded border bg-gray-50 md:col-span-2">
          <div class="flex items-center justify-between mb-1"><span class="font-medium text-gray-800">Mitigate hallucinations</span><span class="text-[10px] px-2 py-0.5 rounded bg-indigo-100 text-indigo-700">RAG / Hybrid</span></div>
          <p class="text-gray-600 leading-snug">Ground facts with retrieval first. Fine-tune helps style & refusal patterns but <strong>does not replace grounding</strong>.</p>
        </div>
      </div>
      <p class="text-[11px] text-gray-500 mt-3">Heuristic cues; validate with quantitative evals before investing in training runs.</p>
    </div>
    <div class="bg-emerald-50 p-4 rounded-lg border border-emerald-200">
      <h4 class="font-semibold text-emerald-900 mb-2">‚úÖ Metrics Before Fine-tuning</h4>
      <ul class="text-sm text-emerald-800 space-y-1">
        <li><strong>Retrieval hit rate</strong> ‚â• 75%? If not, fix retrieval first.</li>
        <li><strong>Grounded answer rate</strong> ‚â• 80%? If low with good hit rate ‚Üí synthesis layer issue.</li>
        <li><strong>Domain perplexity ratio</strong> > 1.3 vs base ‚Üí indicates distribution gap.</li>
        <li><strong>Format error rate</strong> > 10% ‚Üí consider adapter / constrained decoding.</li>
        <li><strong>Personalization value</strong>: measurable uplift (‚â•15%) from user/cohort context?</li>
      </ul>
    </div>
    <div class="bg-red-50 p-4 rounded-lg border-l-4 border-red-400">
      <h4 class="font-semibold text-red-900 mb-2">‚ö†Ô∏è Pitfalls</h4>
      <ul class="text-sm text-red-800 space-y-1">
        <li>Premature fine-tune for volatile knowledge (better: RAG updates).</li>
        <li>Ignoring retrieval diagnostics before blaming the model.</li>
        <li>Adapter stacking without marginal gain measurement.</li>
        <li>Full fine-tune causing narrow over-specialization.</li>
        <li>No holdout eval harness ‚Üí silent regression risk.</li>
      </ul>
    </div>
  </div>
